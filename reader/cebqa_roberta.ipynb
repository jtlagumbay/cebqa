{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35600d84c9c441a1bf5087f6931098b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb71b2b6ebb47fcae9c055e42523dba",
              "IPY_MODEL_b747173077a94a02a3b63550fb56e893",
              "IPY_MODEL_9756c56f2427460e880d65b33c22ab04"
            ],
            "layout": "IPY_MODEL_8ac5b1b23e934f09a8d0f562dbf1d1a4"
          }
        },
        "ddb71b2b6ebb47fcae9c055e42523dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847142aa5dc648958c6e435cd1826939",
            "placeholder": "​",
            "style": "IPY_MODEL_6efd3309f7194629818d5e927f9dd96a",
            "value": "Map: 100%"
          }
        },
        "b747173077a94a02a3b63550fb56e893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53677c412e35461bb6543eb314de698f",
            "max": 2762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9350d63bc43e4ef397ed475011fd1cab",
            "value": 2762
          }
        },
        "9756c56f2427460e880d65b33c22ab04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63b8b94daea4ca7b6c48bd6f8fc701b",
            "placeholder": "​",
            "style": "IPY_MODEL_7e64c4b0c01c49018778f7fe48fce76c",
            "value": " 2762/2762 [00:02&lt;00:00, 1312.88 examples/s]"
          }
        },
        "8ac5b1b23e934f09a8d0f562dbf1d1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847142aa5dc648958c6e435cd1826939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efd3309f7194629818d5e927f9dd96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53677c412e35461bb6543eb314de698f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9350d63bc43e4ef397ed475011fd1cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e63b8b94daea4ca7b6c48bd6f8fc701b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e64c4b0c01c49018778f7fe48fce76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtlagumbay/cebqa/blob/main/reader/cebqa_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CebQA Reader Component**\n",
        "Pretrained model: RoBERTa"
      ],
      "metadata": {
        "id": "otq_L0hL6e2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "fKdMhYwS7344"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_8cT2Gi-EAG",
        "outputId": "017eab75-103c-4dbc-b6f4-d58a1019c28f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, load_dataset\n",
        "from evaluate import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import XLMRobertaForQuestionAnswering, TrainingArguments, Trainer, XLMRobertaTokenizerFast, EarlyStoppingCallback, pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from huggingface_hub import login\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VGIEDXaL73ZW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "q2596jflKFZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b8b911-1204-4134-8dd1-698a5580a256"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Constants**"
      ],
      "metadata": {
        "id": "3quPalaN_3Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CEBQA_DATASET = \"jhoannarica/cebquad\"\n",
        "DRIVE_ROOT = \"/content/drive/Shareddrives/cebqa_roberta/xlmr\"\n",
        "OUTPUT_DIRECTORY = \"training_output\"\n",
        "LOGS_DIRECTORY = \"LOGS\"\n",
        "MODEL_DIRECTORY = \"model\"\n",
        "TOKENIZER_DIRECTORY = \"tokenizer\""
      ],
      "metadata": {
        "id": "VuU1OcfI_5UJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utils**"
      ],
      "metadata": {
        "id": "4yzn4D2wKyWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_TIMESTAMP = \"\"\n",
        "def timestamp(append):\n",
        "  return datetime.datetime.now().strftime(\"%Y-%m-%d_%H\")+\"-\"+str(append)\n",
        "\n",
        "def get_output_directory():\n",
        "  return f\"{DRIVE_ROOT}/{BATCH_TIMESTAMP}/{OUTPUT_DIRECTORY}\"\n",
        "\n",
        "def get_logs_directory():\n",
        "  return f\"{DRIVE_ROOT}/{BATCH_TIMESTAMP}/{LOGS_DIRECTORY}\"\n",
        "\n",
        "def get_model_directory():\n",
        "  return f\"{DRIVE_ROOT}/{BATCH_TIMESTAMP}/{MODEL_DIRECTORY}\"\n",
        "\n",
        "def get_tokenizer_directory():\n",
        "  return f\"{DRIVE_ROOT}/{BATCH_TIMESTAMP}/{TOKENIZER_DIRECTORY}\""
      ],
      "metadata": {
        "id": "RT6PmYJ3K0W1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mo06-PLpM5wK",
        "outputId": "91adcf4d-35df-4b83-8fd0-1e3fdafc8aac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2025-03-08_07-2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "a7eEcbNh6w1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access dataset"
      ],
      "metadata": {
        "id": "ICMgS9hi_X9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p1_d7Fdx4Gmd"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(CEBQA_DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][120]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT27aUa3KMlG",
        "outputId": "63068e40-9347-43e9-92b2-9f5515549097"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '01529-002',\n",
              " 'article_id': 1529,\n",
              " 'article_title': 'Tourist van nahulog kay driver nakatulog',\n",
              " 'article_body': 'Nangalandig sa emergency room sa Badian District Hospital sa Brgy. Poblacion, Badian, habagatang Sugbo, ang upat ka mga turista ug drayber sa van nga ilang gisakyan human naaksidente sa alas 3:40 sa kaadlawon sa Biyernes, Nobiyembre 17, 2023, sa Brgy. Poblacion. Ang drayber nakatulog kay hayan lapoy pa kini sa iyang kapin sa 100 ka kilometro nga biyahe sa amihanang Sugbo. Hinuon minor injuries lang ang naangkon sa mga biktima busa nakagawas ra dayon sa ospital human matambali ug mahiling. Basi sa nakuhang kasayuran sa Superbalita sa Cebu gikan sa kasaligang tinubdan, nailhan ang mga biktima nga turista nga puro taga San Antonio, Tondo, Manila, nga sila si Antonietto Avila Libunao, 64, minyo; iyang asawa nga si Carmen Pacione; Lorence Pacis Paclibon , 40, minyo; ug anak niini nga si Pacomios Pacis Paclibon, 5. Samtang ang drayber nga naangol giila nga si Emeniano Jorge Pacto Pacuan, 24, ulitawo, taga Lamintak Sur, Medellin, amihanang Sugbo. Matod sa tinubdan nga si Pacuan gikan naghatod sa iyang laing guests sa norte sa Sugbo. Pagkahuman, sa mga ala 2 sa kaadlawon sa Nobiyembre 17, niadto siya sa Mactan International Airport aron pagkuha sa mao nga mga turista. Ang grupo padung sa lungsod sa Samboan, Sugbo, apan pag-abot sa taytayan sa Poblacion, Badian nakatagpilaw si Pacuan ug nahasimang ang sakyanan ug nahulog kilid sa bridge. Wa kini malahos sa sapa kay nasangit sa kanipaan. Dali sila nga gipangdala sa tambalanan sa emergency responders. Paglabay sa pipila ka mga oras, nakagawas ra silang tanan sa tambalanan.',\n",
              " 'question': 'Unsa ang kahimtang sa mga biktima human sa aksidente?',\n",
              " 'context': {'end': 493,\n",
              "  'start': 375,\n",
              "  'text': 'Hinuon minor injuries lang ang naangkon sa mga biktima busa nakagawas ra dayon sa ospital human matambali ug mahiling.'},\n",
              " 'answer': {'end': 26, 'start': 7, 'text': 'minor injuries lang'},\n",
              " 'context_start': 375,\n",
              " 'context_end': 493,\n",
              " 'answer_start': 7,\n",
              " 'answer_end': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to track the longest article\n",
        "longest_article = None\n",
        "max_length = 0\n",
        "\n",
        "# Iterate through each article in the train dataset\n",
        "for article in dataset[\"train\"]:\n",
        "    # Concatenate article_body and context\n",
        "    combined_text = article[\"article_body\"] + article[\"question\"]\n",
        "\n",
        "    # Calculate the length of the combined text\n",
        "    combined_length = len(combined_text)\n",
        "\n",
        "    # Update if this article is the longest found so far\n",
        "    if combined_length > max_length:\n",
        "        max_length = combined_length\n",
        "        longest_article = article\n",
        "\n",
        "# Print the longest article and its length\n",
        "print(f\"Longest combined article length: {max_length}\")\n",
        "print(f\"Longest article: {longest_article}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4pe3xzNR5hn",
        "outputId": "53f6f656-ae1e-47b1-e267-d6f0d1a60bc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest combined article length: 5911\n",
            "Longest article: {'id': '00127-003', 'article_id': 127, 'article_title': 'Senado tensiyonado atol sa pag-imbestigar ni Balderas', 'article_body': 'Puno sa tensyon atol sa imbestigasyon sa Senado sa gi-raid nga ilegal nga Pogo hub niadtong Lunes, Septiyembre 9, 2024, tungod kay ang mga magbabalaod nangasuko ni dismissed Bamban, Tarlac Mayor Aretha Balderas, kinsa nagdumili sa pagtubag sa ilang mga pangutana. Samtang ang mga magbabalaod nangutana kung giunsa niya ug ang pipila ka mga miyembro sa iyang pamilya mibiya sa nasod, si Balderas nagdumili sa paghingalan sa tawo nga nagpahigayon sa ilang pag-ikyas, tungod sa kahadlok sa iyang kinabuhi. Gisuwat hinuon niya ang ngalan sa tawo sa usa ka papel sa hangyo ni Senate President Pro Tempore Stanford Baldomar. Gihangyo ni Balderas ang mga magbabalaod nga dili isulti og kusog ang ngalan. \"Do not tell the senators what to do with the information. Pinagbibigyan ka namin isulat sa papel,\" matod ni Senate Committee on Women, Children, Family Relations, and Gender Equality chair Senator Charina Alcaide. \"Nauubos na ‘yung pasensya namin,\" matod ni Alcaide. KUSTODIYA SA PNPGipahinumdoman ni Alcaide si Balderas nga luwas na siya sa kustodiya sa Philippine National Police (PNP). Si Balderas niingon nga andam siya nga ilhon ang mga ngalan sa mga tawo nga mitabang kaniya apan dili sa publiko alang sa katuyoan sa kaluwasan. \"Gustong-gusto mo pala (sabihin), e di sabihin mo. Nakakapikon ka na. Nakakagigil ka na,\" matod ni Baldomar. Si Balderas niingon nga ang tawo nga nitabang nila sa pagbiya mao usab ang naghimo nga sila makaeskapo. \"Siya nag-initiate. . . Nu’ng una po siya ang nagdesisyon para sa akin,\" matod ni Balderas. \"Actually, hindi po tulong ang hiningi ko sa kanya. Actually, to be exact, medyo pinagsalitaan ko po siya nang hindi maganda,\" dason niya. Si Baldomar nagpadayon nga nakasawsay kang Balderas, nga nag-ingon nga “kabuang” ug “katingad-an” nga dili niya ipahibalo ang ngalan sa tawo nga mitabang kanila. \"Pinagsalitaan mo siya nang masama pero siya ang nag-facilitate ng pagtakas ninyo sa Pilipinas. . . Siyempre ‘pag ako pinagsalitaan mo nang masama, hindi na kita tutulungan,\" matod ni Baldomar. \"Bakit ‘di mo pwedeng i-divulge sa publiko? May sikreto ba kayo? This is just a simple question. Pinagsalitaan mo nang masama, absurd, para sa akin it\\'s weird, tapos siya pa ang tumulong sa iyo na makatakas sa Pilipinas,\" dugang niya. Si Alcaide niingon nga nitumaw na sa nangaging mga hearing ang ngalan sa tawo kinsa, sumala ni Balderas, nitabang kanila. Matod ni Baldomar nga anaa karon sa Taiwan ang giila ni Balderas. Siya usa ka naghupot sa lima ka mga pasaporte. Si Balderas miingon nga wala siya kahibalo sa maong impormasyon. Si Balderas usab miingon nga sila, ang iyang gituohang mga igsuon nga sila si Lebron ug Aching, mibiya sa Pilipinas sakay sa barko, usa ka gabii, niadtong Hulyo. Siya niingon nga misakay sila og yate gikan sa pantalan sa Metro Manila dayon mibalhin sa mas dakong barko sa tungatunga sa kadagatan. Si Balderas miingon nga nagpabilin sila sa lawak sa mas dakong sakayan sulod sa pipila ka adlaw. Wala sila gitugotan sa paggawas o bisan sa pagsusi sa ilang mga cell phone. \"Madilim pa rin po. . . Basta dagat po,\" matod ni Balderas. \"Siguro mga four or three or five (days). Basta matagal po. . . Four days po siguro. . . Hindi po kami pinapalabas. Kung puwede lang umatras, aatras na po ako. . . Nakakatakot po talaga. ¦ Gusto ko na po umuwi. Gusto ko na po bumalik,\" dason niya. Giangkon ni Balderas nga nasayop siya kay gusto siyang moeskapo. NASAYOPSiya miingon nga gikan sa dako nga sakayan, sila mibalhin pag-usab ngadto sa usa ka mas gamay nga sakayan, nga nagdala kanila ngadto sa Malaysia, nga wala mahibalo kon asa sila sa tukma tungod kay wa sila tugoti sa pagtan-aw sa palibot. Ang mga pahayag ni Balderas nagpamatuod sa naunang pagsaysay ni Aching kung giunsa nila pag-ikyas. \"Walang tumulong po ni isang Filipino or Filipina. . . Immigration, wala po. Government officials, wala rin po. Filipino, wala po. Wala pong tumulong,\" matod niya. \"That\\'s impossible. Imposibleng walang tumulong sayo upang makatakas dito sa Pilipinas,\" tubag ni Baldomar. Gipanghimakak usab ni Balderas ang pagbayad sa mga nagpahigayon sa ilang pag-ikyas og P200 milyunes. Gitataw usab niya nga usa siya ka Pinay human siya gihangyo sa pagkompirmar sa fingerprint examination nga gihimo sa National Bureau of Investigation (NBI), nga nagmando nga siya usa ug parehas sa Chinese national nga si Balderas Baldonado Balenti. Gipadayon niya nga ang iyang amahan mao si Balderas Balequia Balestramon ug gilimod nga ang iyang inahan mao si Balgos Balidiong Yi. \"Honestly, hindi ko po alam kung paano nangyari. Basta alam ko ako po si Aretha Balderas. At pasensya na rin po kung hindi kayo naniniwala. ¦Lumaki po ako na alam ko Filipino ako,\" pasabot niya. \"Ang alam ko po (All I know is) I was born in Tarlac,\" dugang niya. Gipasanginlan ni Senador Eulogia Alcano si Balderas nga padayong namakak sa ilang mga nawong. Nagdumili usab si Balderas sa pagtubag sa ubang mga pangutana tungod kay gihangyo niya ang iyang katungod sa pagpasangil sa kaugalingon. Siya misaad, bisan pa, sa pagtubag niini nga mga alegasyon sa atubangan sa tukma nga korte. GI-CONTEMPTSa ikaduhang higayon, si Balderas cited in contempt sa Senado. \"This is a blatant defiance of the legislative’s constitutional power of inquiry. Lumalabas na pinaglalaruan mo ang aming batas at pinapaikot mo ang mga Pilipino, pero ibahin mo ang Senado,\" said Alcaide. Human sa pagdungog, si Balderas gibalik sa PNP Custodial Facility diin siya gitanggong alang sa kasong graft and corruption. Si Balderas gidakop sa Tangerang, Indonesia niadtong Septiyembre 3 pinasikad sa arrest order nga giluwatan sa Senate panel kalabot sa nagpadayong imbestigasyon sa gironda nga ilegal nga Pogo hub sa Bamban, Tarlac. Katapusang higayon nga nitambong siya sa imbestigasyon sa Senado niadtong Mayo. / TPM / SunStar Philippines', 'question': 'Unsa ang hangyo ni Balderas sa mga magbabalaod bahin sa ngalan sa tawo nga nagtabang kaniya?', 'context': {'end': 696, 'start': 619, 'text': 'Gihangyo ni Balderas ang mga magbabalaod nga dili isulti og kusog ang ngalan.'}, 'answer': {'end': 76, 'start': 45, 'text': 'dili isulti og kusog ang ngalan'}, 'context_start': 619, 'context_end': 696, 'answer_start': 45, 'answer_end': 76}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare Dataset**"
      ],
      "metadata": {
        "id": "3-r_lcGs60xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare tokenizer"
      ],
      "metadata": {
        "id": "D-9YTrAlS6sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")"
      ],
      "metadata": {
        "id": "lGZQjrRBS8d5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.model_max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUBZf_XbUih3",
        "outputId": "e52a42e9-a150-4b2e-be60-f46b673c63f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "hqG6RvzTS-mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_incomplete_examples(example):\n",
        "    # Ensure both \"question\" and \"context\" exist and are non-empty\n",
        "    return \"question\" in example and example[\"question\"] and \\\n",
        "           \"context\" in example and \"text\" in example[\"context\"] and \\\n",
        "           example[\"context\"][\"text\"] and example[\"answer\"][\"text\"]\n"
      ],
      "metadata": {
        "id": "RJmFpqXfihcH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    context_text = [context.get(\"text\", \"\") for context in examples.get(\"context\", [{}])]\n",
        "    question_text = examples.get(\"question\", [\"\"])\n",
        "\n",
        "    tokenized_examples = tokenizer(\n",
        "        question_text,\n",
        "        context_text,\n",
        "        truncation=\"only_second\",  # Truncate only the context\n",
        "        max_length=512,            # Limit input length\n",
        "        stride=128,                # Add a sliding window\n",
        "        return_overflowing_tokens=True,  # Handle long contexts\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    sample_mapping = tokenized_examples[\"overflow_to_sample_mapping\"]\n",
        "    offset_mapping = tokenized_examples[\"offset_mapping\"]\n",
        "\n",
        "    # Lists to store calculated start and end positions\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        start_token = 0\n",
        "        end_token = 0\n",
        "        sample_index = sample_mapping[i]\n",
        "        answer = examples[\"answer\"][sample_index]\n",
        "\n",
        "        # Handle missing or empty answers\n",
        "        if len(answer[\"text\"]) == 0:\n",
        "            start_positions.append(start_token)\n",
        "            end_positions.append(end_token)\n",
        "            continue\n",
        "\n",
        "        # Get the answer's start and end character positions\n",
        "        start_char = answer[\"start\"]\n",
        "        end_char = answer[\"end\"]\n",
        "\n",
        "        # Get the sequence IDs to identify the context part\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # Identify the start and end of the context\n",
        "        context_start = sequence_ids.index(1)\n",
        "        context_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
        "\n",
        "        # Check if the answer is out of the bounds of the context\n",
        "        if start_char < offsets[context_start][0] or end_char > offsets[context_end][1]:\n",
        "            start_positions.append(start_token)\n",
        "            end_positions.append(end_token)\n",
        "            continue\n",
        "\n",
        "        # Find start and end tokens for the answer\n",
        "        start_token = next(\n",
        "            (idx for idx, offset in enumerate(offsets)\n",
        "            if offset[0] <= start_char <= offset[1]),\n",
        "            None\n",
        "        )\n",
        "        end_token = next(\n",
        "            (idx for idx, offset in enumerate(offsets)\n",
        "            if offset[0] <= end_char <= offset[1]),\n",
        "            None\n",
        "        )\n",
        "\n",
        "        if start_token is None:\n",
        "            raise ValueError(\"Start character position not found in token offsets.\")\n",
        "\n",
        "        if end_token is None:\n",
        "            raise ValueError(\"Start character position not found in token offsets.\")\n",
        "\n",
        "        start_positions.append(start_token)\n",
        "        end_positions.append(end_token)\n",
        "\n",
        "    # Add start and end positions to the tokenized examples\n",
        "    tokenized_examples[\"start_positions\"] = start_positions\n",
        "    tokenized_examples[\"end_positions\"] = end_positions\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset = dataset.filter(filter_incomplete_examples).map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "EDWQ_moz64VR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "35600d84c9c441a1bf5087f6931098b9",
            "ddb71b2b6ebb47fcae9c055e42523dba",
            "b747173077a94a02a3b63550fb56e893",
            "9756c56f2427460e880d65b33c22ab04",
            "8ac5b1b23e934f09a8d0f562dbf1d1a4",
            "847142aa5dc648958c6e435cd1826939",
            "6efd3309f7194629818d5e927f9dd96a",
            "53677c412e35461bb6543eb314de698f",
            "9350d63bc43e4ef397ed475011fd1cab",
            "e63b8b94daea4ca7b6c48bd6f8fc701b",
            "7e64c4b0c01c49018778f7fe48fce76c"
          ]
        },
        "outputId": "ffd5d5d6-3198-49fe-9e28-1732e6c8a55a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2762 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35600d84c9c441a1bf5087f6931098b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[\"train\"].features"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKdD_1Y0XTVH",
        "outputId": "fcdeaddf-0fcb-4e0f-c2e3-f37a2d3d2d02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'article_id': Value(dtype='int64', id=None),\n",
              " 'article_title': Value(dtype='string', id=None),\n",
              " 'article_body': Value(dtype='string', id=None),\n",
              " 'question': Value(dtype='string', id=None),\n",
              " 'context': {'end': Value(dtype='int64', id=None),\n",
              "  'start': Value(dtype='int64', id=None),\n",
              "  'text': Value(dtype='string', id=None)},\n",
              " 'answer': {'end': Value(dtype='int64', id=None),\n",
              "  'start': Value(dtype='int64', id=None),\n",
              "  'text': Value(dtype='string', id=None)},\n",
              " 'context_start': Value(dtype='int64', id=None),\n",
              " 'context_end': Value(dtype='int64', id=None),\n",
              " 'answer_start': Value(dtype='int64', id=None),\n",
              " 'answer_end': Value(dtype='int64', id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'offset_mapping': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
              " 'overflow_to_sample_mapping': Value(dtype='int64', id=None),\n",
              " 'start_positions': Value(dtype='int64', id=None),\n",
              " 'end_positions': Value(dtype='int64', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Splitting"
      ],
      "metadata": {
        "id": "c5NOLjCS7wYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset[\"train\"]\n",
        "val_dataset = tokenized_dataset[\"validation\"]\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "gqZN7rgM705O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e4c46a-08a3-4dea-eec1-763d9464f440"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'article_id', 'article_title', 'article_body', 'question', 'context', 'answer', 'context_start', 'context_end', 'answer_start', 'answer_end', 'input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'start_positions', 'end_positions'],\n",
              "    num_rows: 19340\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "k_fiMlMM8SMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-Trained RoBERTa"
      ],
      "metadata": {
        "id": "uSTMRkFf8GgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLMRobertaForQuestionAnswering.from_pretrained(\"xlm-roberta-base\")\n"
      ],
      "metadata": {
        "id": "6NttjYb58RG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72acb272-f165-4e9f-a574-b7277a17c6a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping"
      ],
      "metadata": {
        "id": "Y4RupQI5LpfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping parameters\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=3,  # Number of evaluations with no improvement before stopping\n",
        "    early_stopping_threshold=0.0  # Minimum change in the metric to qualify as an improvement\n",
        ")"
      ],
      "metadata": {
        "id": "ANAgY7XdLrSc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Argument"
      ],
      "metadata": {
        "id": "aWmbCFT-8azK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to normalize text for comparison\n",
        "def normalize_text(text):\n",
        "    \"\"\"Lowercase and remove punctuation, articles, and extra whitespace.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove punctuation and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "# Function to compute F1 score\n",
        "def compute_f1(pred, truth):\n",
        "    pred_tokens = normalize_text(pred).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "\n",
        "    # Calculate common tokens\n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "\n",
        "    # Precision and Recall\n",
        "    precision = len(common_tokens) / len(pred_tokens)\n",
        "    recall = len(common_tokens) / len(truth_tokens)\n",
        "\n",
        "    # F1 score\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Function to compute Exact Match (EM)\n",
        "def compute_exact_match(pred, truth):\n",
        "    return int(normalize_text(pred) == normalize_text(truth))\n",
        "\n",
        "# Function to compute Sentence Match\n",
        "def compute_sentence_match(pred, truth):\n",
        "    pred_normalized = normalize_text(pred)\n",
        "    truth_normalized = normalize_text(truth)\n",
        "    return int(pred_normalized in truth_normalized or truth_normalized in pred_normalized)"
      ],
      "metadata": {
        "id": "da3dA89fe5od"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_qa_predictions(examples, start_logits, end_logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Convert model logits into readable answers.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(start_logits)):\n",
        "        start_idx = np.argmax(start_logits[i])  # Best start index\n",
        "        end_idx = np.argmax(end_logits[i])  # Best end index\n",
        "\n",
        "        # Ensure valid span\n",
        "        if start_idx >= len(examples[\"input_ids\"][i]) or end_idx >= len(examples[\"input_ids\"][i]):\n",
        "            predictions.append(\"\")\n",
        "            continue\n",
        "\n",
        "        if start_idx > end_idx:  # If invalid prediction\n",
        "            predictions.append(\"\")\n",
        "            continue\n",
        "\n",
        "        # Decode the predicted answer\n",
        "        input_ids = examples[\"input_ids\"][i]\n",
        "        answer_tokens = input_ids[start_idx : end_idx + 1]\n",
        "        prediction = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "StAVyBSG2aEC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load(\"squad\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # print(f\"\\n\\neval pred\")\n",
        "    # print(eval_pred)\n",
        "    logits, labels = eval_pred\n",
        "    # print(f\"\\n\\nlogits\")\n",
        "    # print(logits)\n",
        "    # print(f\"\\n\\nlabels\")\n",
        "    # print(labels)\n",
        "    start_logits, end_logits = logits\n",
        "    # print(f\"\\n\\nstart_logits\")\n",
        "    # print(start_logits)\n",
        "    # print(f\"\\n\\nend_logits\")\n",
        "    # print(end_logits)\n",
        "    # Convert logits to text predictions\n",
        "    predictions = postprocess_qa_predictions(val_dataset, start_logits, end_logits, tokenizer)\n",
        "\n",
        "    # Format references correctly\n",
        "    references = [\n",
        "        {\"id\": str(i), \"answers\": {\"text\": [data[\"answer\"][\"text\"]], \"answer_start\": [data[\"answer\"][\"start\"]]}}\n",
        "        for i, data in enumerate(val_dataset.select)\n",
        "    ]\n",
        "\n",
        "    print(references)\n",
        "\n",
        "    # Compute F1\n",
        "    return metric.compute(predictions=[{\"id\": str(i), \"prediction_text\": pred} for i, pred in enumerate(predictions)], references=references)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "kUAjFHGhtSbM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset[0]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loMtSNGwMH7x",
        "outputId": "61fa01e3-675c-4c83-af15-b4b35c99f46a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '01543-003',\n",
              " 'article_id': 1543,\n",
              " 'article_title': 'Japanese music video, nakig-collab sa Pinoy artists, midaog na sab',\n",
              " 'article_body': 'ANG siyudad sa Hadano, Kanagawa Prefecture, Japan mipahigayon sa ilang 2nd Hadastragram movie contest niadtong Nobiyembre 6, 2023. Moabot ngadto sa 195 ka entry nga gisalmot diin ang \"Bathroom Orchestra Instrumental\" music video sa Japanese musician-film maker Jonneper Padil, a. k. a. iwapt, ang gideklarar nga grand prix champion. Ang maong music video adunay collaboration sa Filipino musician nga naglakip nilang Erlinda Leones ug Randy Lepasana, drummer sa OPM band nga Neocolours. Ang maong awit nga gi-compose ni iwapt gi-record sa Manila niadtong 2010. Ang iyang music video nag-promote sa Hadano City nga nagpakita sa inila nga underground spring water sa maong dapit. Gi-showcase sab ang ilang nature-rich parks ug observatories, sikat nila nga delicacies, ug ang dapit sa Hadano diin gipahigayon ang 2020 Tokyo Olympics.',\n",
              " 'question': 'Kinsa ang nagdaog nga music video sa Hadastragram movie contest?',\n",
              " 'context': {'end': 333,\n",
              "  'start': 0,\n",
              "  'text': 'ANG siyudad sa Hadano, Kanagawa Prefecture, Japan mipahigayon sa ilang 2nd Hadastragram movie contest niadtong Nobiyembre 6, 2023. Moabot ngadto sa 195 ka entry nga gisalmot diin ang \"Bathroom Orchestra Instrumental\" music video sa Japanese musician-film maker Jonneper Padil, a. k. a. iwapt, ang gideklarar nga grand prix champion. '},\n",
              " 'answer': {'end': 275, 'start': 261, 'text': 'Jonneper Padil'},\n",
              " 'context_start': 0,\n",
              " 'context_end': 333,\n",
              " 'answer_start': 261,\n",
              " 'answer_end': 275,\n",
              " 'input_ids': [0,\n",
              "  37029,\n",
              "  433,\n",
              "  348,\n",
              "  4197,\n",
              "  85,\n",
              "  1663,\n",
              "  817,\n",
              "  19612,\n",
              "  1202,\n",
              "  57,\n",
              "  185693,\n",
              "  2816,\n",
              "  25561,\n",
              "  14277,\n",
              "  62757,\n",
              "  32,\n",
              "  2,\n",
              "  2,\n",
              "  49754,\n",
              "  78,\n",
              "  9076,\n",
              "  12409,\n",
              "  57,\n",
              "  185693,\n",
              "  157,\n",
              "  4,\n",
              "  59510,\n",
              "  21256,\n",
              "  1914,\n",
              "  17928,\n",
              "  6644,\n",
              "  4,\n",
              "  15758,\n",
              "  324,\n",
              "  61118,\n",
              "  1758,\n",
              "  9480,\n",
              "  57,\n",
              "  41455,\n",
              "  116,\n",
              "  2208,\n",
              "  185693,\n",
              "  2816,\n",
              "  25561,\n",
              "  14277,\n",
              "  62757,\n",
              "  300,\n",
              "  712,\n",
              "  18176,\n",
              "  438,\n",
              "  40165,\n",
              "  36300,\n",
              "  305,\n",
              "  4,\n",
              "  140429,\n",
              "  5,\n",
              "  2501,\n",
              "  94445,\n",
              "  817,\n",
              "  71,\n",
              "  188,\n",
              "  57,\n",
              "  91809,\n",
              "  156,\n",
              "  42805,\n",
              "  817,\n",
              "  3016,\n",
              "  2317,\n",
              "  18397,\n",
              "  45,\n",
              "  73,\n",
              "  348,\n",
              "  44,\n",
              "  8023,\n",
              "  42294,\n",
              "  306,\n",
              "  198624,\n",
              "  73750,\n",
              "  289,\n",
              "  58,\n",
              "  19612,\n",
              "  1202,\n",
              "  57,\n",
              "  148926,\n",
              "  19612,\n",
              "  3378,\n",
              "  9,\n",
              "  8551,\n",
              "  6,\n",
              "  55474,\n",
              "  21240,\n",
              "  86,\n",
              "  1264,\n",
              "  22017,\n",
              "  379,\n",
              "  4,\n",
              "  10,\n",
              "  5,\n",
              "  472,\n",
              "  5,\n",
              "  10,\n",
              "  5,\n",
              "  17,\n",
              "  634,\n",
              "  6328,\n",
              "  4,\n",
              "  348,\n",
              "  38630,\n",
              "  343,\n",
              "  320,\n",
              "  147,\n",
              "  817,\n",
              "  9963,\n",
              "  22135,\n",
              "  102995,\n",
              "  5,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'offset_mapping': [[0, 0],\n",
              "  [0, 3],\n",
              "  [3, 5],\n",
              "  [6, 9],\n",
              "  [10, 13],\n",
              "  [13, 15],\n",
              "  [15, 17],\n",
              "  [18, 21],\n",
              "  [22, 27],\n",
              "  [28, 33],\n",
              "  [34, 36],\n",
              "  [37, 41],\n",
              "  [41, 45],\n",
              "  [45, 49],\n",
              "  [50, 55],\n",
              "  [56, 63],\n",
              "  [63, 64],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 3],\n",
              "  [4, 6],\n",
              "  [6, 8],\n",
              "  [8, 11],\n",
              "  [12, 14],\n",
              "  [15, 19],\n",
              "  [19, 21],\n",
              "  [21, 22],\n",
              "  [23, 27],\n",
              "  [27, 31],\n",
              "  [32, 35],\n",
              "  [35, 38],\n",
              "  [38, 42],\n",
              "  [42, 43],\n",
              "  [44, 49],\n",
              "  [50, 52],\n",
              "  [52, 55],\n",
              "  [55, 58],\n",
              "  [58, 61],\n",
              "  [62, 64],\n",
              "  [65, 70],\n",
              "  [71, 72],\n",
              "  [72, 74],\n",
              "  [75, 79],\n",
              "  [79, 83],\n",
              "  [83, 87],\n",
              "  [88, 93],\n",
              "  [94, 101],\n",
              "  [102, 104],\n",
              "  [104, 106],\n",
              "  [106, 110],\n",
              "  [111, 113],\n",
              "  [113, 116],\n",
              "  [116, 121],\n",
              "  [122, 123],\n",
              "  [123, 124],\n",
              "  [125, 129],\n",
              "  [129, 130],\n",
              "  [131, 133],\n",
              "  [133, 137],\n",
              "  [138, 141],\n",
              "  [141, 142],\n",
              "  [142, 144],\n",
              "  [145, 147],\n",
              "  [148, 151],\n",
              "  [152, 154],\n",
              "  [155, 160],\n",
              "  [161, 164],\n",
              "  [165, 167],\n",
              "  [167, 170],\n",
              "  [170, 173],\n",
              "  [174, 176],\n",
              "  [176, 178],\n",
              "  [179, 182],\n",
              "  [183, 184],\n",
              "  [184, 186],\n",
              "  [186, 190],\n",
              "  [190, 192],\n",
              "  [193, 202],\n",
              "  [203, 213],\n",
              "  [213, 215],\n",
              "  [215, 216],\n",
              "  [217, 222],\n",
              "  [223, 228],\n",
              "  [229, 231],\n",
              "  [232, 240],\n",
              "  [241, 246],\n",
              "  [246, 249],\n",
              "  [249, 250],\n",
              "  [250, 254],\n",
              "  [255, 256],\n",
              "  [255, 260],\n",
              "  [261, 264],\n",
              "  [264, 266],\n",
              "  [266, 269],\n",
              "  [270, 273],\n",
              "  [273, 275],\n",
              "  [275, 276],\n",
              "  [277, 278],\n",
              "  [278, 279],\n",
              "  [280, 281],\n",
              "  [281, 282],\n",
              "  [283, 284],\n",
              "  [284, 285],\n",
              "  [286, 287],\n",
              "  [287, 289],\n",
              "  [289, 291],\n",
              "  [291, 292],\n",
              "  [293, 296],\n",
              "  [297, 300],\n",
              "  [300, 302],\n",
              "  [302, 305],\n",
              "  [305, 307],\n",
              "  [308, 311],\n",
              "  [312, 317],\n",
              "  [318, 322],\n",
              "  [323, 331],\n",
              "  [331, 332],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0],\n",
              "  [0, 0]],\n",
              " 'overflow_to_sample_mapping': 0,\n",
              " 'start_positions': 91,\n",
              " 'end_positions': 95}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    BATCH_TIMESTAMP = timestamp(trial.number)\n",
        "    # Suggest values for hyperparameters\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-4)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 2, 5)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-3, 0.1)\n",
        "\n",
        "    # Define training arguments with suggested values\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=get_output_directory(),\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        logging_dir=get_logs_directory(),\n",
        "        logging_steps=10,\n",
        "        save_total_limit=3,\n",
        "        bf16=True  # Best for A100\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[early_stopping_callback]\n",
        "    )\n",
        "\n",
        "     # Train and evaluate the model\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(eval_results)\n",
        "\n",
        "    model.save_pretrained(get_model_directory())\n",
        "    tokenizer.save_pretrained(get_output_directory())\n",
        "\n",
        "    # Optimize based on F1 Score (maximize it)\n",
        "    return eval_results[\"eval_f1\"]"
      ],
      "metadata": {
        "id": "reOEvEudn3e1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYC6iYvRw4Qt",
        "outputId": "1abe3364-724c-41f8-ba88-d73f2183cb6a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.9270097017288208,\n",
              " 'eval_runtime': 4.4091,\n",
              " 'eval_samples_per_second': 626.435,\n",
              " 'eval_steps_per_second': 19.732,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=1)\n",
        "\n",
        "# Get the best trial\n",
        "best_trial = study.best_trial\n",
        "# Print best trial number and its hyperparameters\n",
        "print(f\"Best Trial: {best_trial.number}\")\n",
        "print(\"Best Hyperparameters:\", best_trial.params)\n",
        "print(f\"Best F1 Score: {best_trial.value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "bxfPiSNSp001",
        "outputId": "36d62d02-bcb5-42a4-8a1b-d40213b0bf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-08 10:15:14,461] A new study created in memory with name: no-name-46c06be6-4b60-466b-8d5f-8d4ff5f0d155\n",
            "<ipython-input-21-4aa743529139>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-4)\n",
            "<ipython-input-21-4aa743529139>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-3, 0.1)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjtlagumbay\u001b[0m (\u001b[33mjtlagumbay-university-of-the-philippines\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_101522-mzg4llk9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface/runs/mzg4llk9' target=\"_blank\">/content/drive/Shareddrives/cebqa_roberta/xlmr//training_output</a></strong> to <a href='https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface' target=\"_blank\">https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface/runs/mzg4llk9' target=\"_blank\">https://wandb.ai/jtlagumbay-university-of-the-philippines/huggingface/runs/mzg4llk9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2419' max='9672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2419/9672 02:40 < 08:00, 15.08 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='346' max='346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [346/346 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the model**"
      ],
      "metadata": {
        "id": "85j__wkg9Mny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating"
      ],
      "metadata": {
        "id": "KPv14zFU9Pye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "HryRtAmv9T8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  model\n",
        "  tokenizer\n",
        "except:\n",
        "    model_path = \"/content/drive/Shareddrives/cebqa_roberta/xlmr/2025-02-25_01/model\"\n",
        "    tokenizer_path = \"/content/drive/Shareddrives/cebqa_roberta/xlmr/2025-02-25_01/tokenizer\"\n",
        "\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "36M64RE79TuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc6c35b-64aa-47b4-83cd-cee20a24e4be"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dataset[\"test\"].shuffle(seed=60).select(range(50))\n",
        "\n",
        "# List to store results\n",
        "results_list = []\n",
        "\n",
        "# Iterate through each sample in test_dataset\n",
        "for sample in test_dataset:\n",
        "    question = sample[\"question\"]\n",
        "    context = sample[\"article_body\"]\n",
        "    expected_answer = sample[\"answer\"][\"text\"] if sample[\"answer\"][\"text\"] else \"N/A\"  # Handle empty answers\n",
        "\n",
        "    # Get model prediction\n",
        "    model_output = qa_pipeline(question=question, context=context)\n",
        "    actual_answer = model_output[\"answer\"]\n",
        "\n",
        "    # Append results\n",
        "    results_list.append({\n",
        "        \"Question\": question,\n",
        "        \"Expected Answer\": expected_answer,\n",
        "        \"Actual Answer\": actual_answer\n",
        "    })\n",
        "\n",
        "for result in results_list:\n",
        "    expected = result[\"Expected Answer\"]\n",
        "    actual = result[\"Actual Answer\"]\n",
        "\n",
        "    result[\"F1 Score\"] = compute_f1(actual, expected)\n",
        "    result[\"Exact Match\"] = compute_exact_match(actual, expected)\n",
        "    result[\"Sentence Match\"] = compute_sentence_match(actual, expected)\n",
        "\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "df = pd.DataFrame(results_list)\n",
        "\n",
        "# Display as a table\n",
        "display(df)"
      ],
      "metadata": {
        "id": "4dstIijiNWjH",
        "outputId": "1cda9e5e-2b7f-4583-dfa3-d4368eab79a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             Question  \\\n",
              "0   Pila ang kita nga nakolekta sa Kapitolyo gikan...   \n",
              "1   Unsa ang gibuhat sa biktima sa dili pa siya gi...   \n",
              "2   Unsa ang gibuhat sa Mandaue City Government ar...   \n",
              "3   Kinsa ang gipanglantawan nga mobisita sa econo...   \n",
              "4   Unsa ang nahitabo kang Inchak Lydwena tungod s...   \n",
              "5   Unsang petsa ug oras nahitabo ang buy-bust sa ...   \n",
              "6               Nganong gihimo ni Baliwan ang krimen?   \n",
              "7   Unsa ang gibutyag ni Acabal bahin sa ilang kol...   \n",
              "8                       Kinsa ang mayor sa Lapu-Lapu?   \n",
              "9   Unsa ang gibalaod ni Espiras nga mahitabo sa e...   \n",
              "10          asa nisibat ang gunman human sa pagpusil?   \n",
              "11  Unsa ang nakit-an sa unahan sa dapit sa akside...   \n",
              "12  Unsa ang mahitabo kon adunay labaw sa 50 ka mg...   \n",
              "13  Kinsa ang hepe nga nagmandar sa pag-responde s...   \n",
              "14  Kinsa ang naghatag og impormasyon bahin sa sun...   \n",
              "15           Unsa nga motibo ang gisusi sa kapulisan?   \n",
              "16  Pila ka tao ang nakalas sa mga kaso sa pagpamu...   \n",
              "17  Unsa ang gitala nga balor sa mga kabtangan nga...   \n",
              "18      Pila ka mga bala ang nakuha sa mga operatiba?   \n",
              "19  Unsa ang giangkon sa suspek bahin sa pagpatay ...   \n",
              "20  Unsa ang gibuhat sa pamilya ni Eliezar aron ma...   \n",
              "21  Asa narekober ang uban pang mga kinawat nga to...   \n",
              "22  Pilang tuig ang validity sa CPCs nga gihatag s...   \n",
              "23        Kinsa ang nagdala sa biktima sa tambalanan?   \n",
              "24                Unsa ang gipasidan-an sa mga dalaw?   \n",
              "25  Pila ka minutos sila naghulat nga wala molihok...   \n",
              "26  Unsay nahitabo sa mensahe nga gipadala ni Reym...   \n",
              "27  Asa si Abaya niadto aron pagtambong sa kalihuk...   \n",
              "28        Asa gipakita nga nagpatrolya ang mga polis?   \n",
              "29              Kanus-a misira ang The Lapena Social?   \n",
              "30  Kinsa ang live-in partner ni Crys nga nangayo ...   \n",
              "31  Unsa ang gibuhat sa PNP aron batukan ang cyber...   \n",
              "32        Gikan kinsa ang nadawat nga suwat sa NBI 7?   \n",
              "33  Unsa pa ang gihatag nga benepisyo kang Arvie B...   \n",
              "34  Pila ang silot sa mga malapason sa ika-lima ng...   \n",
              "35                   Kinsa ang biktima sa pagpamusil?   \n",
              "36          Kinsa ang hepe nga nag-imbestiga sa kaso?   \n",
              "37  Unsa ang nakuha sa mga operatiba sa buy-bust o...   \n",
              "38  Unsa ang kahimtang sa building sa Madridejos E...   \n",
              "39                       Asa nahitabo ang pagpamusil?   \n",
              "40  Kinsa ang naghisgot bahin sa pagtinabangay sa ...   \n",
              "41  Unsa ang mga industriya nga kasagaran mosalmot...   \n",
              "42  Unsa ang gisulti sa upat ka mga regular nga em...   \n",
              "43  Unsa ang kinahanglan mahuman sa dili pa ang Pa...   \n",
              "44           Asa nga lugar diin nahulog ang wing van?   \n",
              "45               Kanus-a nahitabo ang pagpusil patay?   \n",
              "46  Pila ka local government units (LGUs) ang nagd...   \n",
              "47  Unsay plano ni Abangan kung gikinahanglan ang ...   \n",
              "48          Kinsa ang nangunay sa pagkuha sa sakayan?   \n",
              "49  Kinsa ang investigator sa kaso nga nakuryentih...   \n",
              "\n",
              "                                      Expected Answer  \\\n",
              "0                                       P303 milyunes   \n",
              "1                          nagpalit lang og ice water   \n",
              "2   pag-integrate sa mental health care ngadto sa ...   \n",
              "3                     Russian President Bumagat Dioyo   \n",
              "4                         nilupad lusot sa windshield   \n",
              "5   alas 8:10 sa Biyernes Santo sa gabii, Marso 29...   \n",
              "6                          tungod usab sa iyang selos   \n",
              "7   ila usab nga gipauswag ang ilang koleksyon sa ...   \n",
              "8                                       Junard Abalos   \n",
              "9                                       domino effect   \n",
              "10              pinaagi sa pagsulod sa gate sa Pier 4   \n",
              "11    tricycle nga tangkaltangkal nga nabalintuwad na   \n",
              "12  ang mga espesyal nga polling center mahimong i...   \n",
              "13                              P/Maj. Ivy Jim Denila   \n",
              "14                                    Doc RD Gobalani   \n",
              "15                                  ilegal nga drugas   \n",
              "16                                               Duha   \n",
              "17                                    P11. 6 milyunes   \n",
              "18                                   unom ka mga bala   \n",
              "19   iyang gipatay ang iyang lolo kay siyay giunha...   \n",
              "20               nidangop na og Binisaya ug mananagna   \n",
              "21                                    sa balay niini.   \n",
              "22                                    Seven (7) years   \n",
              "23                                        ambulansiya   \n",
              "24          dili mosuway sa pagpalusot og kontrabando   \n",
              "25                                         12 minutos   \n",
              "26                  naka-message pa si Reymous kaniya   \n",
              "27                                  sa Estados Unidos   \n",
              "28                                          sa Toledo   \n",
              "29                                         Pebrero 20   \n",
              "30                                 Manuelito de Jesus   \n",
              "31  nagbansay og mga personnel aron batukan ang cy...   \n",
              "32                 Bureau of Internal Revenue (BIR 7)   \n",
              "33                           kuwarta ug grocery items   \n",
              "34                                          P1 milyon   \n",
              "35                                     Menor Mercadal   \n",
              "36                           P/Lt. Col. Karyo Paguyod   \n",
              "37              lima ka mga pakete sa gituohang shabu   \n",
              "38                                      hingpit ugdaw   \n",
              "39                                   Barangay Patupat   \n",
              "40     Acting Cebu City Mayor Jhonnylou Ghen Abalayan   \n",
              "41  business process outsourcing companies, superm...   \n",
              "42  wala sila makadawat sa ilang binuwang suholan ...   \n",
              "43                         tanang pag-ayo ug pag-usab   \n",
              "44  Barangay Yupisan, lungsod sa Pamplona, Negros ...   \n",
              "45                                Nobiyembre 12, 2023   \n",
              "46                       22 ka local government units   \n",
              "47           personal niyang iduso ang iyang desisyon   \n",
              "48                                      Necasio Genio   \n",
              "49                          P/Master Sgt. Arce Dexter   \n",
              "\n",
              "                                        Actual Answer  F1 Score  Exact Match  \\\n",
              "0                                       P628 milyunes  0.500000            0   \n",
              "1                   Rhamsontal Eprol Labor Melgarejo,  0.000000            0   \n",
              "2            community-based mental health initiative  0.210526            0   \n",
              "3                                 children’s hospital  0.000000            0   \n",
              "4                         nilupad lusot sa windshield  1.000000            1   \n",
              "5                      alas 10:55 sa Miyerkules Santo  0.470588            0   \n",
              "6                          tungod usab sa iyang selos  1.000000            1   \n",
              "7   nagbutang na sila og pukot sa mga utlanan sa sapa  0.275862            0   \n",
              "8                                       Junard Abalos  1.000000            1   \n",
              "9               dili na mangayo og usbaw sa plitehan.  0.000000            0   \n",
              "10                            iyang itom nga scooter,  0.000000            0   \n",
              "11                        tricycle nga tangkaltangkal  0.666667            0   \n",
              "12            dili kini magpahigayon sa onsite voting  0.111111            0   \n",
              "13                             P/Maj. Ivy Jim Denila.  1.000000            1   \n",
              "14                                   Doc RD Gobalani,  1.000000            1   \n",
              "15                                 person of interest  0.000000            0   \n",
              "16                                 Sylvian Barnachea,  0.000000            0   \n",
              "17                                       39 ka alarma  0.000000            0   \n",
              "18                                   unom ka mga bala  1.000000            1   \n",
              "19                           Galarpe Mirasol Davantes  0.000000            0   \n",
              "20                 na-missing nidangop na og Binisaya  0.666667            0   \n",
              "21                    Dave Gertrudes Dennis Dayagdal,  0.000000            0   \n",
              "22                                   Five (5) years,”  0.333333            0   \n",
              "23                     P/Lt. Colonel Porferio Kramer,  0.000000            0   \n",
              "24                                    nagdala og gift  0.222222            0   \n",
              "25                                         12 minutos  1.000000            1   \n",
              "26                     namatay usab ang iyang amahan.  0.000000            0   \n",
              "27                                     Estados Unidos  0.800000            0   \n",
              "28                                   Ralf Dimayacyac,  0.000000            0   \n",
              "29                                  Oktubre 17, 2017.  0.000000            0   \n",
              "30                                Manuelito de Jesus,  1.000000            1   \n",
              "31                         nagbansay og mga personnel  0.615385            0   \n",
              "32                 Bureau of Internal Revenue (BIR 7)  1.000000            1   \n",
              "33                           kuwarta ug grocery items  1.000000            1   \n",
              "34                                Gobernador Abalayan  0.000000            0   \n",
              "35                                    Menor Mercadal,  1.000000            1   \n",
              "36                          P/Lt. Col. Karyo Paguyod,  1.000000            1   \n",
              "37        high value individual sa ilegal nga drugas.  0.142857            0   \n",
              "38                           faulty electrical wiring  0.000000            0   \n",
              "39                              .357 Magnum revolver.  0.000000            0   \n",
              "40                                      Calvo Pangag,  0.000000            0   \n",
              "41                     maghimo og online transactions  0.000000            0   \n",
              "42            “uncontroverted and biased information”  0.000000            0   \n",
              "43                         renovation ug repair works  0.200000            0   \n",
              "44                                  Barangay Yupisan,  0.444444            0   \n",
              "45                               Nobiyembre 12, 2023.  1.000000            1   \n",
              "46                       22 ka local government units  1.000000            1   \n",
              "47                        Presidente Lois Alarcon Jr.  0.000000            0   \n",
              "48                                     Necasio Genio,  1.000000            1   \n",
              "49                         P/Master Sgt. Arce Dexter,  1.000000            1   \n",
              "\n",
              "    Sentence Match  \n",
              "0                0  \n",
              "1                0  \n",
              "2                0  \n",
              "3                0  \n",
              "4                1  \n",
              "5                0  \n",
              "6                1  \n",
              "7                0  \n",
              "8                1  \n",
              "9                0  \n",
              "10               0  \n",
              "11               1  \n",
              "12               0  \n",
              "13               1  \n",
              "14               1  \n",
              "15               0  \n",
              "16               0  \n",
              "17               0  \n",
              "18               1  \n",
              "19               0  \n",
              "20               0  \n",
              "21               0  \n",
              "22               0  \n",
              "23               0  \n",
              "24               0  \n",
              "25               1  \n",
              "26               0  \n",
              "27               1  \n",
              "28               0  \n",
              "29               0  \n",
              "30               1  \n",
              "31               1  \n",
              "32               1  \n",
              "33               1  \n",
              "34               0  \n",
              "35               1  \n",
              "36               1  \n",
              "37               0  \n",
              "38               0  \n",
              "39               0  \n",
              "40               0  \n",
              "41               0  \n",
              "42               0  \n",
              "43               0  \n",
              "44               1  \n",
              "45               1  \n",
              "46               1  \n",
              "47               0  \n",
              "48               1  \n",
              "49               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36c0f48a-274b-49ea-910d-63d7078abf7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Expected Answer</th>\n",
              "      <th>Actual Answer</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>Sentence Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pila ang kita nga nakolekta sa Kapitolyo gikan...</td>\n",
              "      <td>P303 milyunes</td>\n",
              "      <td>P628 milyunes</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unsa ang gibuhat sa biktima sa dili pa siya gi...</td>\n",
              "      <td>nagpalit lang og ice water</td>\n",
              "      <td>Rhamsontal Eprol Labor Melgarejo,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unsa ang gibuhat sa Mandaue City Government ar...</td>\n",
              "      <td>pag-integrate sa mental health care ngadto sa ...</td>\n",
              "      <td>community-based mental health initiative</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kinsa ang gipanglantawan nga mobisita sa econo...</td>\n",
              "      <td>Russian President Bumagat Dioyo</td>\n",
              "      <td>children’s hospital</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsa ang nahitabo kang Inchak Lydwena tungod s...</td>\n",
              "      <td>nilupad lusot sa windshield</td>\n",
              "      <td>nilupad lusot sa windshield</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Unsang petsa ug oras nahitabo ang buy-bust sa ...</td>\n",
              "      <td>alas 8:10 sa Biyernes Santo sa gabii, Marso 29...</td>\n",
              "      <td>alas 10:55 sa Miyerkules Santo</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Nganong gihimo ni Baliwan ang krimen?</td>\n",
              "      <td>tungod usab sa iyang selos</td>\n",
              "      <td>tungod usab sa iyang selos</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Unsa ang gibutyag ni Acabal bahin sa ilang kol...</td>\n",
              "      <td>ila usab nga gipauswag ang ilang koleksyon sa ...</td>\n",
              "      <td>nagbutang na sila og pukot sa mga utlanan sa sapa</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kinsa ang mayor sa Lapu-Lapu?</td>\n",
              "      <td>Junard Abalos</td>\n",
              "      <td>Junard Abalos</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Unsa ang gibalaod ni Espiras nga mahitabo sa e...</td>\n",
              "      <td>domino effect</td>\n",
              "      <td>dili na mangayo og usbaw sa plitehan.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>asa nisibat ang gunman human sa pagpusil?</td>\n",
              "      <td>pinaagi sa pagsulod sa gate sa Pier 4</td>\n",
              "      <td>iyang itom nga scooter,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Unsa ang nakit-an sa unahan sa dapit sa akside...</td>\n",
              "      <td>tricycle nga tangkaltangkal nga nabalintuwad na</td>\n",
              "      <td>tricycle nga tangkaltangkal</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Unsa ang mahitabo kon adunay labaw sa 50 ka mg...</td>\n",
              "      <td>ang mga espesyal nga polling center mahimong i...</td>\n",
              "      <td>dili kini magpahigayon sa onsite voting</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Kinsa ang hepe nga nagmandar sa pag-responde s...</td>\n",
              "      <td>P/Maj. Ivy Jim Denila</td>\n",
              "      <td>P/Maj. Ivy Jim Denila.</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Kinsa ang naghatag og impormasyon bahin sa sun...</td>\n",
              "      <td>Doc RD Gobalani</td>\n",
              "      <td>Doc RD Gobalani,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Unsa nga motibo ang gisusi sa kapulisan?</td>\n",
              "      <td>ilegal nga drugas</td>\n",
              "      <td>person of interest</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Pila ka tao ang nakalas sa mga kaso sa pagpamu...</td>\n",
              "      <td>Duha</td>\n",
              "      <td>Sylvian Barnachea,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Unsa ang gitala nga balor sa mga kabtangan nga...</td>\n",
              "      <td>P11. 6 milyunes</td>\n",
              "      <td>39 ka alarma</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Pila ka mga bala ang nakuha sa mga operatiba?</td>\n",
              "      <td>unom ka mga bala</td>\n",
              "      <td>unom ka mga bala</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Unsa ang giangkon sa suspek bahin sa pagpatay ...</td>\n",
              "      <td>iyang gipatay ang iyang lolo kay siyay giunha...</td>\n",
              "      <td>Galarpe Mirasol Davantes</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Unsa ang gibuhat sa pamilya ni Eliezar aron ma...</td>\n",
              "      <td>nidangop na og Binisaya ug mananagna</td>\n",
              "      <td>na-missing nidangop na og Binisaya</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Asa narekober ang uban pang mga kinawat nga to...</td>\n",
              "      <td>sa balay niini.</td>\n",
              "      <td>Dave Gertrudes Dennis Dayagdal,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Pilang tuig ang validity sa CPCs nga gihatag s...</td>\n",
              "      <td>Seven (7) years</td>\n",
              "      <td>Five (5) years,”</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Kinsa ang nagdala sa biktima sa tambalanan?</td>\n",
              "      <td>ambulansiya</td>\n",
              "      <td>P/Lt. Colonel Porferio Kramer,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Unsa ang gipasidan-an sa mga dalaw?</td>\n",
              "      <td>dili mosuway sa pagpalusot og kontrabando</td>\n",
              "      <td>nagdala og gift</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Pila ka minutos sila naghulat nga wala molihok...</td>\n",
              "      <td>12 minutos</td>\n",
              "      <td>12 minutos</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unsay nahitabo sa mensahe nga gipadala ni Reym...</td>\n",
              "      <td>naka-message pa si Reymous kaniya</td>\n",
              "      <td>namatay usab ang iyang amahan.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Asa si Abaya niadto aron pagtambong sa kalihuk...</td>\n",
              "      <td>sa Estados Unidos</td>\n",
              "      <td>Estados Unidos</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Asa gipakita nga nagpatrolya ang mga polis?</td>\n",
              "      <td>sa Toledo</td>\n",
              "      <td>Ralf Dimayacyac,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Kanus-a misira ang The Lapena Social?</td>\n",
              "      <td>Pebrero 20</td>\n",
              "      <td>Oktubre 17, 2017.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Kinsa ang live-in partner ni Crys nga nangayo ...</td>\n",
              "      <td>Manuelito de Jesus</td>\n",
              "      <td>Manuelito de Jesus,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Unsa ang gibuhat sa PNP aron batukan ang cyber...</td>\n",
              "      <td>nagbansay og mga personnel aron batukan ang cy...</td>\n",
              "      <td>nagbansay og mga personnel</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Gikan kinsa ang nadawat nga suwat sa NBI 7?</td>\n",
              "      <td>Bureau of Internal Revenue (BIR 7)</td>\n",
              "      <td>Bureau of Internal Revenue (BIR 7)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Unsa pa ang gihatag nga benepisyo kang Arvie B...</td>\n",
              "      <td>kuwarta ug grocery items</td>\n",
              "      <td>kuwarta ug grocery items</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Pila ang silot sa mga malapason sa ika-lima ng...</td>\n",
              "      <td>P1 milyon</td>\n",
              "      <td>Gobernador Abalayan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Kinsa ang biktima sa pagpamusil?</td>\n",
              "      <td>Menor Mercadal</td>\n",
              "      <td>Menor Mercadal,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Kinsa ang hepe nga nag-imbestiga sa kaso?</td>\n",
              "      <td>P/Lt. Col. Karyo Paguyod</td>\n",
              "      <td>P/Lt. Col. Karyo Paguyod,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Unsa ang nakuha sa mga operatiba sa buy-bust o...</td>\n",
              "      <td>lima ka mga pakete sa gituohang shabu</td>\n",
              "      <td>high value individual sa ilegal nga drugas.</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Unsa ang kahimtang sa building sa Madridejos E...</td>\n",
              "      <td>hingpit ugdaw</td>\n",
              "      <td>faulty electrical wiring</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Asa nahitabo ang pagpamusil?</td>\n",
              "      <td>Barangay Patupat</td>\n",
              "      <td>.357 Magnum revolver.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Kinsa ang naghisgot bahin sa pagtinabangay sa ...</td>\n",
              "      <td>Acting Cebu City Mayor Jhonnylou Ghen Abalayan</td>\n",
              "      <td>Calvo Pangag,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Unsa ang mga industriya nga kasagaran mosalmot...</td>\n",
              "      <td>business process outsourcing companies, superm...</td>\n",
              "      <td>maghimo og online transactions</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Unsa ang gisulti sa upat ka mga regular nga em...</td>\n",
              "      <td>wala sila makadawat sa ilang binuwang suholan ...</td>\n",
              "      <td>“uncontroverted and biased information”</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Unsa ang kinahanglan mahuman sa dili pa ang Pa...</td>\n",
              "      <td>tanang pag-ayo ug pag-usab</td>\n",
              "      <td>renovation ug repair works</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Asa nga lugar diin nahulog ang wing van?</td>\n",
              "      <td>Barangay Yupisan, lungsod sa Pamplona, Negros ...</td>\n",
              "      <td>Barangay Yupisan,</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Kanus-a nahitabo ang pagpusil patay?</td>\n",
              "      <td>Nobiyembre 12, 2023</td>\n",
              "      <td>Nobiyembre 12, 2023.</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Pila ka local government units (LGUs) ang nagd...</td>\n",
              "      <td>22 ka local government units</td>\n",
              "      <td>22 ka local government units</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Unsay plano ni Abangan kung gikinahanglan ang ...</td>\n",
              "      <td>personal niyang iduso ang iyang desisyon</td>\n",
              "      <td>Presidente Lois Alarcon Jr.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Kinsa ang nangunay sa pagkuha sa sakayan?</td>\n",
              "      <td>Necasio Genio</td>\n",
              "      <td>Necasio Genio,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Kinsa ang investigator sa kaso nga nakuryentih...</td>\n",
              "      <td>P/Master Sgt. Arce Dexter</td>\n",
              "      <td>P/Master Sgt. Arce Dexter,</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36c0f48a-274b-49ea-910d-63d7078abf7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36c0f48a-274b-49ea-910d-63d7078abf7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36c0f48a-274b-49ea-910d-63d7078abf7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a696ef90-764d-42bf-b2dd-9f573450ec59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a696ef90-764d-42bf-b2dd-9f573450ec59')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a696ef90-764d-42bf-b2dd-9f573450ec59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9595d021-55aa-4abd-95fb-47b44aecff96\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9595d021-55aa-4abd-95fb-47b44aecff96 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Kinsa ang hepe nga nagmandar sa pag-responde sa insidente?\",\n          \"Asa nahitabo ang pagpamusil?\",\n          \"Kinsa ang live-in partner ni Crys nga nangayo og tabang?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"P/Maj. Ivy Jim Denila\",\n          \"Barangay Patupat\",\n          \"Manuelito de Jesus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"P/Maj. Ivy Jim Denila.\",\n          \".357 Magnum revolver.\",\n          \"Manuelito de Jesus,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.441412858560292,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.2222222222222222,\n          0.6153846153846153,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exact Match\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence Match\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_f1 = df[\"F1 Score\"].mean()\n",
        "avg_em = df[\"Exact Match\"].mean()\n",
        "avg_sm = df[\"Sentence Match\"].mean()\n",
        "\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
        "print(f\"Average Exact Match: {avg_em:.4f}\")\n",
        "print(f\"Average Sentence Match: {avg_sm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CfBTk0RgPVH",
        "outputId": "085991f8-1420-470b-dae0-2189d2e14e6a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average F1 Score: 0.4332\n",
            "Average Exact Match: 0.3200\n",
            "Average Sentence Match: 0.4000\n"
          ]
        }
      ]
    }
  ]
}