{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtlagumbay/cebqa/blob/main/retriever/bm_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otq_L0hL6e2P"
      },
      "source": [
        "# **QA Pipeline**\n",
        "\n",
        "1. ElasticSeach Indexer\n",
        "2. BM25 Retriever\n",
        "3. Fine-tuned XLMR Reader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOvUOWAOgjQj"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPzhJswwfHQZ",
        "outputId": "60b9065f-4fff-498b-af40-1a25b6082b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elasticsearch==8.17.2\n",
            "  Downloading elasticsearch-8.17.2-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==8.17.2)\n",
            "  Downloading elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.17.2) (2.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.17.2) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading elasticsearch-8.17.2-py3-none-any.whl (717 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.0/718.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-8.17.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, xxhash, rank_bm25, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, elastic-transport, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, elasticsearch, nvidia-cusolver-cu12, datasets, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 elastic-transport-8.17.1 elasticsearch-8.17.2 evaluate-0.4.3 fsspec-2024.12.0 fuzzywuzzy-0.18.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rank_bm25-0.2.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install elasticsearch==8.17.2 transformers datasets evaluate rank_bm25 nltk fuzzywuzzy sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kOoiI65fzNT"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade --no-cache-dir numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd5lCHKLfzNT",
        "outputId": "2ed43c13-4931-4cf9-c398-00d556077b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2596jflKFZi",
        "outputId": "e8b6e13e-9f7c-4453-a924-7c07b0e2c937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import bulk\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer, XLMRobertaTokenizerFast, DPRQuestionEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "from datasets import Dataset, load_dataset\n",
        "import re\n",
        "from evaluate import load\n",
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "from fuzzywuzzy import fuzz\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import faiss\n",
        "import unicodedata\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ppd3LkTdLVbR"
      },
      "outputs": [],
      "source": [
        "CEBQA_DATASET = \"jhoannarica/cebquad_split\"\n",
        "SUPERBALITA_DATASET = \"jhoannarica/superbalita_split\"\n",
        "ELASTIC_URL = \"https://tender-separately-mudfish.ngrok-free.app\"\n",
        "# ELASTIC_URL = \"http://localhost:9200\"\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/My Drive\"\n",
        "# DRIVE_ROOT = \"/Users/jhoannaricalagumbay/Library/CloudStorage/GoogleDrive-jtlagumbay@up.edu.ph/My Drive\"\n",
        "\n",
        "READER_FOLDER = \"/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13\"\n",
        "DPR_FOLDER = \"/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/dpr/2025-04-16_03-37\"\n",
        "\n",
        "\n",
        "CURRENT_MODEL = DRIVE_ROOT + READER_FOLDER + \"/model\"\n",
        "CURRENT_TOKENIZER = DRIVE_ROOT + READER_FOLDER + \"/tokenizer\"\n",
        "INDEX_NAME = \"superbalita\"\n",
        "K = 10\n",
        "BM25 = \"bm25\"\n",
        "FAISS = \"faiss\"\n",
        "HYBRID = \"hybrid\"\n",
        "\n",
        "CEBQA_DPR_MODEL = DRIVE_ROOT + DPR_FOLDER + \"/model\"\n",
        "CEBQA_DPR_TOKENIZER = DRIVE_ROOT + DPR_FOLDER + \"/tokenizer\"\n",
        "DPR_CONTEXT_ENCODER = \"voidful/dpr-ctx_encoder-bert-base-multilingual\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8h9VpP0gnfK"
      },
      "source": [
        "# Indexer\n",
        "\n",
        "Start ElasticSearch Locally:\n",
        "1. Start ES docker\n",
        "2. Start NGROK: `ngrok http --url=tender-separately-mudfish.ngrok-free.app 9200`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://tender-separately-mudfish.ngrok-free.app"
      ],
      "metadata": {
        "id": "x2FXx5GEp4-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show elasticsearch"
      ],
      "metadata": {
        "id": "MbGqIp13lBVA",
        "outputId": "d9545d3c-bc89-4bae-ff87-9435e2d9563c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: elasticsearch\n",
            "Version: 8.17.2\n",
            "Summary: Python client for Elasticsearch\n",
            "Home-page: https://github.com/elastic/elasticsearch-py\n",
            "Author: \n",
            "Author-email: Elastic Client Library Maintainers <client-libs@elastic.co>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: elastic-transport\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXMwFDbHvpi7",
        "outputId": "a375ad76-fd98-47e4-acde-e65b737d75d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Allow': 'GET,DELETE,HEAD', 'Content-Length': '0', 'Content-Type': 'text/plain; charset=UTF-8', 'Ngrok-Agent-Ips': '202.90.135.62', 'X-Elastic-Product': 'Elasticsearch', 'Date': 'Mon, 21 Apr 2025 16:32:26 GMT'}\n"
          ]
        }
      ],
      "source": [
        "headers = {\n",
        "    \"Origin\": \"https://colab.research.google.com\",\n",
        "     \"Content-Type\": \"application/json\",\n",
        "    \"Accept\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.options(ELASTIC_URL, headers=headers)\n",
        "print(response.headers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCzdjxWMGbQI",
        "outputId": "8d98ebb6-e2e2-4010-e6ff-0317338e2208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/elasticsearch/_sync/client/__init__.py:403: SecurityWarning: Connecting to 'https://tender-separately-mudfish.ngrok-free.app:443' using TLS with verify_certs=False is insecure\n",
            "  _transport = transport_class(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'tender-separately-mudfish.ngrok-free.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': '40645cf85c9d', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'ST_2iQqITE-zmJCo8dlrnw', 'version': {'number': '8.17.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '747663ddda3421467150de0e4301e8d4bc636b0c', 'build_date': '2025-02-05T22:10:57.067596412Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
          ]
        }
      ],
      "source": [
        "es = Elasticsearch([ELASTIC_URL], verify_certs=False, headers=headers, request_timeout=30)\n",
        "print(es.info())\n",
        "# try:\n",
        "#     print(es.transport.perform_request('GET', '/'))\n",
        "# except Exception as e:\n",
        "#     print(\"Error:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IACpNh6CgpD7"
      },
      "outputs": [],
      "source": [
        "class ElasticSearchIndexer:\n",
        "    def __init__(self, index_name=INDEX_NAME):\n",
        "        self.index_name = index_name\n",
        "        self.es = Elasticsearch(ELASTIC_URL)  # Ensure ES is running\n",
        "        print(f\"Initiating ESIndexer {self.index_name}\")\n",
        "\n",
        "    def create_index(self):\n",
        "        \"\"\" Create an index with a text field for BM25 \"\"\"\n",
        "        if not self.es.indices.exists(index=self.index_name):\n",
        "            self.es.indices.create(index=self.index_name, body={\n",
        "                \"settings\": {\n",
        "                    \"number_of_shards\": 1,\n",
        "                    \"number_of_replicas\": 0\n",
        "                },\n",
        "                \"mappings\": {\n",
        "                    \"properties\": {\n",
        "                        \"id\": {\"type\": \"keyword\"},\n",
        "                        \"title\": {\"type\": \"text\"},\n",
        "                        \"body\": {\"type\": \"text\"}\n",
        "                    }\n",
        "                }\n",
        "            })\n",
        "            print(f\"Index '{self.index_name}' created.\")\n",
        "\n",
        "    def index_documents(self, documents):\n",
        "        \"\"\" Bulk index documents into ElasticSearch \"\"\"\n",
        "        actions = [\n",
        "            {\n",
        "                \"_index\": self.index_name,\n",
        "                \"_id\": doc[\"id\"],  # Use document ID for uniqueness\n",
        "                \"_source\": {\n",
        "                    \"id\": doc[\"id\"],\n",
        "                    \"title\": doc[\"pseudonymized_title\"],\n",
        "                    \"body\": doc[\"pseudonymized_body\"]\n",
        "                }\n",
        "            }\n",
        "            for doc in documents\n",
        "        ]\n",
        "        bulk(self.es, actions)\n",
        "        print(f\"Indexed {len(documents)} documents.\")\n",
        "\n",
        "    def index_from_csv(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        documents = df.to_dict(orient=\"records\")  # Convert DataFrame to a list of dicts\n",
        "        self.index_documents(documents)\n",
        "\n",
        "    def index_from_huggingface(self, dataset = SUPERBALITA_DATASET):\n",
        "        dataset_obj = load_dataset(dataset)\n",
        "\n",
        "        # Create the dataset_dict from the loaded dataset object's splits\n",
        "        dataset_dict = {\n",
        "            split_name: split_dataset\n",
        "            for split_name, split_dataset in dataset_obj.items()\n",
        "        }\n",
        "\n",
        "        all_documents = []\n",
        "        for split_name, split_dataset in dataset_dict.items():\n",
        "            documents = split_dataset.to_list()\n",
        "            all_documents.extend(documents)\n",
        "\n",
        "        self.index_documents(all_documents)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNaD93tOiGnj"
      },
      "outputs": [],
      "source": [
        "# # Sample usage\n",
        "# indexer = ElasticSearchIndexer()\n",
        "# indexer.create_index()\n",
        "# indexer.index_from_csv(\"/Users/jhoannaricalagumbay/School/cebqa/dataset/articles_202503120405_author_removed_fixed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjVIRDtt2Kjh"
      },
      "source": [
        "# BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VWU0iGhM2Mr5"
      },
      "outputs": [],
      "source": [
        "class BM25Retriever:\n",
        "    def __init__(self, index_name = INDEX_NAME):\n",
        "        print(f\"Initiating retriever with index_name: {INDEX_NAME}\")\n",
        "        self.indexer = ElasticSearchIndexer(index_name = INDEX_NAME)\n",
        "        # self.indexer.create_index()\n",
        "        # self.indexer.index_from_huggingface()\n",
        "        self.index_name = index_name\n",
        "\n",
        "    def retrieve(self, query, top_k=3):\n",
        "        \"\"\" Retrieve top-k relevant documents using BM25 \"\"\"\n",
        "        print(f\"retrieving {top_k} docs for [{query}]\")\n",
        "        response = self.indexer.es.search(index=self.indexer.index_name, body={\n",
        "            \"query\": {\n",
        "                \"match\": {\n",
        "                    \"body\": query\n",
        "                }\n",
        "            },\n",
        "            \"size\": top_k\n",
        "        })\n",
        "        return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n",
        "\n",
        "    def retrieve_batch(self, queries, top_k=3):\n",
        "        print(f\"Retrieve Batch for {len(queries)} queries\")\n",
        "        \"\"\" Retrieve top-k relevant documents for multiple queries using BM25 in batch mode \"\"\"\n",
        "        if not isinstance(queries, list):\n",
        "            raise ValueError(\"queries should be a list of strings\")\n",
        "\n",
        "        # Multi-search request body\n",
        "        request_body = \"\"\n",
        "        for query in queries:\n",
        "            safe_question = json.dumps(query)\n",
        "            request_body += f'{{\"index\": \"{self.indexer.index_name}\"}}\\n'  # Metadata\n",
        "            request_body += f'{{\"query\": {{\"match\": {{\"body\": {safe_question}}}}}, \"size\": {top_k}}}\\n'  # Query\n",
        "\n",
        "        # Send multi-search request\n",
        "        response = self.indexer.es.msearch(body=request_body)\n",
        "\n",
        "        # # Extract results\n",
        "        # results = []\n",
        "        # for query_response in response[\"responses\"]:\n",
        "        #     retrieved_docs = [hit[\"_source\"] for hit in query_response[\"hits\"][\"hits\"]]\n",
        "        #     results.append(retrieved_docs)\n",
        "\n",
        "        # return results  # List of lists, where each sublist contains retrieved documents for a query\n",
        "\n",
        "        results = []\n",
        "        for query_response in response[\"responses\"]:\n",
        "            retrieved_docs = []\n",
        "            for hit in query_response[\"hits\"][\"hits\"]:\n",
        "                # Create a document that includes both the source content and the score\n",
        "                doc = hit[\"_source\"]\n",
        "                doc[\"score\"] = hit[\"_score\"]  # Add BM25 score from Elasticsearch\n",
        "                retrieved_docs.append(doc)\n",
        "            results.append(retrieved_docs)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def retrieve_batch_query_dict(self, queries_list, top_k=3):\n",
        "        print(f\"Retrieve Batch Dict for {len(queries_list)} queries\")\n",
        "\n",
        "        \"\"\" Retrieve top-k relevant documents for multiple queries using BM25 in batch mode.\n",
        "\n",
        "        Args:\n",
        "            queries_list (list): A list of dictionaries, each containing 'id' and 'question'.\n",
        "            top_k (int): Number of top relevant documents to retrieve per query.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary where keys are query IDs and values are lists of retrieved documents.\n",
        "        \"\"\"\n",
        "        if not isinstance(queries_list, list) or not all(isinstance(q, dict) and 'id' in q and 'question' in q for q in queries_list):\n",
        "            raise ValueError(\"queries_list should be a list of dictionaries with 'id' and 'question' keys\")\n",
        "\n",
        "        # Multi-search request body\n",
        "        request_body = \"\"\n",
        "        query_ids = []  # To track IDs in order\n",
        "        for query in queries_list:\n",
        "            safe_question = json.dumps(query[\"question\"])\n",
        "            query_ids.append(query[\"id\"])\n",
        "            request_body += f'{{\"index\": \"{self.index_name}\"}}\\n'  # Metadata\n",
        "            request_body += f'{{\"query\": {{\"match\": {{\"body\": {safe_question}}}}}, \"size\": {top_k}}}\\n'  # Query\n",
        "\n",
        "        # Send multi-search request\n",
        "        response = self.indexer.es.msearch(body=request_body)\n",
        "\n",
        "        # Extract results and associate with query IDs\n",
        "        results = []\n",
        "        for i, query_response in enumerate(response[\"responses\"]):\n",
        "            # retrieved_docs = [hit[\"_source\"] for hit in query_response[\"hits\"][\"hits\"]]\n",
        "            retrieved_docs = []\n",
        "            for hit in query_response[\"hits\"][\"hits\"]:\n",
        "                # Create a document that includes both the source content and the score\n",
        "                doc = hit[\"_source\"]\n",
        "                doc[\"score\"] = hit[\"_score\"]  # Add BM25 score from Elasticsearch\n",
        "                retrieved_docs.append(doc)\n",
        "            results.append({\n",
        "                \"query_id\": str(query_ids[i]),\n",
        "                \"top_docs\": retrieved_docs\n",
        "            })\n",
        "\n",
        "        return results  # Dictionary format: {id: retrieved_docs}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsSSqnQt2rxX",
        "outputId": "795079f1-1b82-4deb-eb51-753b8e4f1eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating retriever with index_name: superbalita\n",
            "Initiating ESIndexer superbalita\n",
            "Retrieve Batch for 1 queries\n",
            "Retrieved Documents: [[{'id': 286, 'title': 'Gwen: Sugbo nagkahiusa alang sa pagsuporta ni President Alarcon', 'body': 'Atol sa opening salvo program sa 455th Founding Anniversary sa Probinsiya sa Sugbo, Agusto 5, 2024, si Gobernador Edlen Abalayan nanawagan sa tanang gobernador sa pagsuporta sa administrasyon ni Presidente Lois Alarcon Jr. “As we have shown and manifested, we know without any questions and ifs, and or buts, we a united Cebu stand firmly behind the leadership of our president, Lois Alarcon Jr. This is a statement and a commitment, as well as a challenge to my fellow governors. Now more than ever, let our voices ring out in the entire Philippines. . . We need to move forward and we must move forward, and we can only do this with a united country,” pakigpulong sa gobernador. Nagsilbing pinasidunggang dinapit sa maong kalihokan si First Lady Ariane Cabahit-Alarcon. Diin adunay gihimo nga ‘Manifesto of Support’ diin si Gov. Abalayan, Bise gobernadora Abina Tomas III, mga opisyal ingon man ang ubang gobernardor nga mitambong ang mipirma sa maong manifesto alang sa Bagong Pilipinas nga gisaksihan ni FL Alarcon. Lakip sa maong kalihokan ang pagpasiugda og Tabo sa Kapitolyo 2024 nga adunay mga nagkadaiyang lagutmon, produkto gipasigarbo sa nagkadaiyang lungsod ug dakbayan sa probinsiya. Karong adlawa, Agusto 6, ang Civil Service Commission nipagawas og regional advisory nga Special Holiday sa Probinsiya sa Sugbo ug gidaklarar nga way trabaho ang government offices. Samtang pipila ka mga publiko ug pribadong tunghaan sa Sugbo ang way klase. /FVQ', 'score': 28.392431}, {'id': 947, 'title': 'Abalayan miinsister: Abcede Blvd. gipanag-iya sa Kapitolyo', 'body': 'Giinsister ni Cebu Governor Edlen Abalayan nga ang kagamhanan sa probinsya sa Sugbo ang legal nga nanag-iya sa Abcede Blvd. lakip ang tibuok Fuente Rotunda. Kini maoy pamahayag ni Abalayan subay sa pagpadayag sa pipila ka mga politiko pagsupak sa gusto sa gobernador nga ipahunong ang pagtrabaho sa Cebu Bus Rapid Transit (CBRT) project. Si Abalayan nipasabot, “Kaning Kapitolyo nga compound padung sa entire Oseman Boulevard, lakip ang entire Fuente Rotunda, kani nga mga titles naa sa pangalan sa Cebu Provincial Government. In fact part of the road nga naglibot sa rotunda wala nay annotation for a road load ang duna ray annotation for a road lot is a ng twenty-meter wide road lot naa sa atong mga titulo nga nag span from the Capitol paingon sa rotunda, road lot dili bus station. ”Dugang niya nga dunay land-swap deal nga gihimo tali sa kagamhanan sa probinsya sa Sugbo ug Cebu Heights Inc. sa 1930 nga giingong nahimong kontrobersiyal. Bisan og wala kini mag mention og ngalan o apilyedo iyang gibutyag nga ang gihimong land-swap deal tali sa Cebu Height Inc. , nga naglangkob sa Osmena Boulevard ug bahin sa Barngay Banilad giingong nahimong kontrobersiyal. Sa nasayran si kanhi gobernador Cipriano Abcede Jr. nga kaniadto gobernador sa Sugbo mao usab ang presidente sa Cebu Heights Inc. “Although there is a person who believes nga iya pa kuno to manggawas nani ron ang mga kamatuoran unsa gyuý nahitabo between Cebu Heights pagbaligya ngaris probinsya ug ang pagpaniguro nga ang mga yuta nga nagpabilin nga gipanag-iya aning pamilyaha giseguro nga unya nalang pod. Niabot ni Presidential level kaniadto kay nikiha ang pipila ka mga Sugboanon nga ilado usab nga nakakita sila nga naay gihimong land swap between the province of Cebu and Cebu Heights grossly disadvantageous to the Province, mangabutyag ning tanan,” asoy ni Abalayan. Si kanhi Cebu City Mayor Brian Osmena una nang niingon nga posibling mapasakaan og kaso ang gobernador ugaling mopadayon kini pag insister sa pagpahunong sa Cebu Bus Rapid Transit (CBRT) project. Una nang niingon si Osmena nga dili ang probinsya maoy nanag-iya sa tibuok Osmena Boulevard. Giingon ang iyang nitaliwan na nga amahan Cipriano “Serging” Osmena ang nanag-iya sa ubang luna sa may Juana Osmena street paingon sa Guadalupe lakip ang bahin sa luna nga gitukuran sa kapitolyo. “Panungog lang. Panungog lang kay ganahan kaayo ko anang dunay mga nangasuko nga seryoso gyud kaayo. Aslum na kaayo og mga nawong,” dugang niya. Gihagit usab sa gobernador ang mga mohagit kaniya sa pagsusi sa tinuod nga nahitabo sa dili pa mo komento.', 'score': 17.378675}, {'id': 558, 'title': 'Abangan: Gwen ‘di matinud-anon’', 'body': 'Nitiyabaw si Cebu City Mayor Cedie Abangan sa pagduhig sa iyang ngalan ni Cebu Governor Edlen Abalayan sa iyang pagluwat isip sakop sa Partido ng Demokratiko Pilipino Lakas Ng Bayan (PDP-Laban), tungod sa tensyon tali sa gisuspenso nga mayor. Sa usa ka Facebook post sa Miyerkules, Mayo 29, 2024, si Abangan niingon nga ang pagluwat ni Abalayan “simply not truthful,” nga nagkuwestiyon sa iyang loyalty bisan pa mahitabo ang ilang panagbangi. Matod ni Abangan, si Abalayan walay “steady political compass,” ug walay “any record of having steady political principles. ”“I was shocked to see the resignation letter of a person I highly doubt fits the title honorable,” matod ni Abangan. “True or what, I heard that it was a day after Malacañang ordered her to submit an Answer to the Administrative Complaint regarding her interference in the Affairs of Cebu City, she had the temerity of resigning as a member of PDP but not without using my name in vain,” dason ni Abangan. Sa Martes, Mayo 28, gipahibalo ni Abalayan ang iyang pagluwat sa grupo nga nagpadayag nga ang iyang padayon nga pakig-uban sa partido “dili mapadayon. ”Si Abalayan niingon nga ang kasong administratiba ni Abangan, nga gisang-at sa Office of the President ug pagpetisyon sa iyang pagkasuspenso, nakaaghat kaniya sa pagbiya sa partido politikal. Ang reklamo mao ang wa pag-uyon ni Abangan sa gobernador sa iyang memorandum niadtong Pebrero 2024 nga nagmando sa pagpahunong sa bus stop sa Cebu Bus Rapid Transit (CBRT) project atubangan sa Cebu Capitol Building, tungod sa kalapasan sa heritage. “She has no business with Cebu City affairs and should just stay out of it. Pagkatoytoy ning Gobernadora,” dugang ni Abangan. Gidepensahan usab ni Abangan ang iyang panglantaw sa Cebu City nga mahimong “Singapore like with Melbourne features,” sa pagkutlo sa duha ka siyudad nga ika-42 ug siyam sa global ranking ug wala siya masayop sa paggamit niini isip benchmark. “Anyway, there is a reason why Manila and Cebu City are included in global rankings. No other city in these islands,” dugang ni Abangan. Si Abalayan nagdumili sa paghatag og komento sa pasangil ni Abangan batok kaniya.', 'score': 13.910924}]]\n"
          ]
        }
      ],
      "source": [
        "# Sample usage\n",
        "retriever = BM25Retriever()\n",
        "query = ['Unsa ang giingon ni Gobernador Abalayan nga mabuhat ra \"with a united country\"?']\n",
        "top_docs = retriever.retrieve_batch(query)\n",
        "print(\"Retrieved Documents:\", top_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACSdoCoTfzNV"
      },
      "source": [
        "# FAISS Indexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "emJXIlwMfzNV"
      },
      "outputs": [],
      "source": [
        "class FAISSIndexer:\n",
        "    def __init__(self, index_file=\"faiss_index.idx\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", use_fine_tuned = False):\n",
        "        self.index_file = index_file\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(\"Loading DPR multilingual context encoder...\")\n",
        "        self.dpr_tokenizer = DPRContextEncoderTokenizer.from_pretrained(DPR_CONTEXT_ENCODER)\n",
        "        self.dpr_model = DPRContextEncoder.from_pretrained(DPR_CONTEXT_ENCODER)\n",
        "        self.use_fine_tuned = use_fine_tuned\n",
        "        self.index = None\n",
        "        self.documents = []  # Store original text\n",
        "        # self.index_from_csv()\n",
        "        self.index_from_huggingface()\n",
        "        print(\"FAISS Indexer initialized.\")\n",
        "\n",
        "\n",
        "    def encode_contexts_with_dpr(self):\n",
        "        \"\"\"Encode contexts using DPR multilingual context encoder and re-index.\"\"\"\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        device = torch.device(\"cpu\")\n",
        "        self.dpr_model.to(device)\n",
        "        self.dpr_model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = self.dpr_tokenizer(\n",
        "                self.documents,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=512\n",
        "            ).to(device)\n",
        "\n",
        "            embeddings = self.dpr_model(**inputs).pooler_output.cpu().numpy()\n",
        "\n",
        "            if not embeddings.flags['C_CONTIGUOUS']:\n",
        "                embeddings = np.ascontiguousarray(embeddings)\n",
        "\n",
        "            faiss.normalize_L2(embeddings)\n",
        "            return embeddings\n",
        "\n",
        "    def create_index(self, d):\n",
        "        \"\"\"Create a new FAISS index.\"\"\"\n",
        "        self.index = faiss.IndexFlatL2(d)\n",
        "        print(f\"Created FAISS index with dimension {d}.\")\n",
        "\n",
        "    def index_documents(self, documents):\n",
        "        \"\"\"Index documents into FAISS.\"\"\"\n",
        "        self.documents = [doc['pseudonymized_body'] for doc in documents]\n",
        "        self.article_ids = [doc['id'] for doc in documents]\n",
        "        self.titles = [doc['pseudonymized_title'] for doc in documents]\n",
        "\n",
        "        if self.use_fine_tuned:\n",
        "            embeddings = self.encode_contexts_with_dpr()\n",
        "        else:\n",
        "            embeddings = self.model.encode(self.documents, convert_to_numpy=True)\n",
        "\n",
        "        d = embeddings.shape[1]\n",
        "\n",
        "        if self.index is None:\n",
        "            self.create_index(d)\n",
        "\n",
        "        self.index.add(embeddings)\n",
        "        print(f\"Indexed {len(documents)} documents into FAISS.\")\n",
        "        self.save_index()\n",
        "\n",
        "    def index_from_csv(self, file_path):\n",
        "        \"\"\"Load documents from a CSV file and index them.\"\"\"\n",
        "        df = pd.read_csv(file_path)\n",
        "        documents = df.to_dict(orient=\"records\")\n",
        "        self.index_documents(documents)\n",
        "\n",
        "    def index_from_huggingface(self, dataset = SUPERBALITA_DATASET):\n",
        "        dataset_obj = load_dataset(dataset)\n",
        "\n",
        "        # Create the dataset_dict from the loaded dataset object's splits\n",
        "        dataset_dict = {\n",
        "            split_name: split_dataset\n",
        "            for split_name, split_dataset in dataset_obj.items()\n",
        "        }\n",
        "        all_documents = []\n",
        "        for split_name, split_dataset in dataset_dict.items():\n",
        "            documents = split_dataset.to_list()\n",
        "            all_documents.extend(documents)\n",
        "\n",
        "        self.index_documents(all_documents)\n",
        "\n",
        "    def save_index(self):\n",
        "        \"\"\"Save FAISS index to disk.\"\"\"\n",
        "        faiss.write_index(self.index, self.index_file)\n",
        "        print(f\"FAISS index saved to {self.index_file}.\")\n",
        "\n",
        "    def load_index(self):\n",
        "        \"\"\"Load FAISS index from disk.\"\"\"\n",
        "        self.index = faiss.read_index(self.index_file)\n",
        "        print(f\"FAISS index loaded from {self.index_file}.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T0jb0opFfzNV"
      },
      "outputs": [],
      "source": [
        "class FAISSRetriever:\n",
        "    def __init__(\n",
        "            self,\n",
        "            q_encoder = DPRQuestionEncoder.from_pretrained(CEBQA_DPR_MODEL),\n",
        "            q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(CEBQA_DPR_TOKENIZER),\n",
        "            index_file=\"faiss_index.idx\",\n",
        "            top_k=3,\n",
        "            # device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "            device = \"cpu\",\n",
        "            use_fine_tuned = False\n",
        "        ):\n",
        "        print(\"Initializing FAISS Retriever\")\n",
        "        self.indexer = FAISSIndexer(index_file=index_file, use_fine_tuned=use_fine_tuned)\n",
        "        self.top_k = top_k\n",
        "        self.use_fine_tuned = use_fine_tuned\n",
        "        self.q_encoder = q_encoder\n",
        "        self.q_tokenizer = q_tokenizer\n",
        "        self.device = device\n",
        "\n",
        "        # Move model to the appropriate device\n",
        "        self.q_encoder.to(device)\n",
        "        self.q_encoder.eval()\n",
        "\n",
        "    def encode_query(self, query):\n",
        "        \"\"\"Encode the query using the fine-tuned question encoder.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            inputs = self.q_tokenizer(\n",
        "                query,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=64\n",
        "            ).to(self.device)\n",
        "\n",
        "            embeddings = self.q_encoder(**inputs).pooler_output.cpu().numpy()\n",
        "\n",
        "            # Ensure embeddings are C-contiguous for FAISS\n",
        "            if not embeddings.flags['C_CONTIGUOUS']:\n",
        "                embeddings = np.ascontiguousarray(embeddings)\n",
        "\n",
        "            # Normalize embeddings for cosine similarity\n",
        "            faiss.normalize_L2(embeddings)\n",
        "\n",
        "            return embeddings\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        \"\"\"Retrieve top-k relevant documents using FAISS.\"\"\"\n",
        "        if self.use_fine_tuned:\n",
        "            query_embedding = self.encode_query([query])\n",
        "        else:\n",
        "            query_embedding = self.indexer.model.encode([query], convert_to_numpy=True)\n",
        "\n",
        "        D, I = self.indexer.index.search(query_embedding, self.top_k)\n",
        "        # print(D, I)\n",
        "        results = [\n",
        "            {\n",
        "                \"rank\": rank + 1,\n",
        "                \"score\": float(D[0][rank]),\n",
        "                \"id\": self.indexer.article_ids[idx],\n",
        "                \"title\": self.indexer.titles[idx],\n",
        "                \"body\": self.indexer.documents[idx],\n",
        "            }\n",
        "            for rank, idx in enumerate(I[0]) if idx < len(self.indexer.documents)\n",
        "        ]\n",
        "        return results\n",
        "\n",
        "    def retrieve_batch(self, queries):\n",
        "\n",
        "        print(f\"processing {len(queries)}\")\n",
        "        \"\"\"Retrieve top-k relevant documents for multiple queries.\"\"\"\n",
        "        questions = [query[\"question\"] for query in queries]\n",
        "        if self.use_fine_tuned:\n",
        "            query_embeddings = self.encode_query([query])\n",
        "        else:\n",
        "            query_embeddings = self.indexer.model.encode(questions, convert_to_numpy=True)\n",
        "        D, I = self.indexer.index.search(query_embeddings, self.top_k)\n",
        "        # print(f\"done {len(D)}\")\n",
        "        results = []\n",
        "        for query_idx, query in enumerate(queries):\n",
        "            print(f\"query idx: {query_idx}\")\n",
        "            retrieved_docs = [\n",
        "                {\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"score\": float(D[query_idx][rank]),\n",
        "                    \"text\": self.indexer.documents[idx]\n",
        "                }\n",
        "                for rank, idx in enumerate(I[query_idx]) if idx < len(self.indexer.documents)\n",
        "            ]\n",
        "            results.append({\"query\": query, \"top_docs\": retrieved_docs})\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhQrz7eDfzNV"
      },
      "outputs": [],
      "source": [
        "# # Initialize the FAISS indexer\n",
        "# indexer = FAISSIndexer(index_file=\"faiss_index.idx\")\n",
        "\n",
        "# Index documents from a CSV file\n",
        "# # Save the FAISS index for later use\n",
        "# indexer.save_index()\n",
        "\n",
        "# indexer = FAISSIndexer(index_file=\"faiss_index.idx\")\n",
        "# indexer.load_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnZAxJ11fzNW"
      },
      "outputs": [],
      "source": [
        "# Initialize the retriever with the loaded indexer\n",
        "# retriever = FAISSRetriever(index_file=\"faiss_index.idx\", top_k=K)\n",
        "\n",
        "# # Retrieve relevant documents for a single query\n",
        "# query = \"kanus-a ang palarong pambansa??\"\n",
        "# results = retriever.retrieve(query)\n",
        "\n",
        "# # Print retrieved documents\n",
        "# print(results)\n",
        "\n",
        "\n",
        "# Retrieve relevant documents for a single query\n",
        "# query = [{\"question\": \"kanus-a ang palarong pambansa?\"}, {\"question\":\"Kinsa ang hepe sa Cebu Police?\"}]\n",
        "# results = retriever.retrieve_batch(query)\n",
        "\n",
        "# # Print retrieved documents\n",
        "# for res in results:\n",
        "#     print(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwo3IpR3--n"
      },
      "source": [
        "# Reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZAb9aRYL4AYY"
      },
      "outputs": [],
      "source": [
        "class Reader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path = CURRENT_MODEL,\n",
        "        tokenizer_path = CURRENT_TOKENIZER\n",
        "      ):\n",
        "        print(f\"Initiating reader with model: {model_path}\")\n",
        "        model_best = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "        tokenizer_best = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "        # device = torch.device(\"mps\")\n",
        "        # device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        device = \"cpu\"\n",
        "        self.qa_pipeline = pipeline(\n",
        "            \"question-answering\",\n",
        "            model=model_best,\n",
        "            tokenizer=tokenizer_best,\n",
        "            device=device\n",
        "            )\n",
        "\n",
        "    def extract_answer_batch(self, queries_list, top_docs):\n",
        "        print(f\"Extracting batch answer for {len(queries_list)} queries\")\n",
        "        qa_dataset = Dataset.from_dict({\n",
        "          \"question\": [queries_list[\"question\"] for doc in top_docs['top_docs']] ,\n",
        "          \"context\": [doc['body'] for doc in top_docs['top_docs']]\n",
        "        })\n",
        "\n",
        "        return self.qa_pipeline(qa_dataset)\n",
        "\n",
        "    def extract_answer(self, question, documents, num_chunks = 1, overlap = 0.3):\n",
        "        print(f\"extracting answer for {question}\")\n",
        "        \"\"\" Find the best answer from retrieved documents while keeping metadata \"\"\"\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for doc in documents:\n",
        "            if num_chunks == 1:\n",
        "                contexts = [doc[\"body\"]]\n",
        "            else:\n",
        "                contexts = self.chunk_text(doc[\"body\"],  num_chunks, overlap)\n",
        "\n",
        "            for context in contexts:\n",
        "            #   print(question)\n",
        "            #   print(context)\n",
        "              result = self.qa_pipeline(question=question, context = context)\n",
        "              if result[\"score\"] > best_score:\n",
        "                  best_result = {\n",
        "                      \"article_id\": doc[\"id\"],\n",
        "                      \"title\": doc[\"title\"],\n",
        "                      \"body\": doc[\"body\"],\n",
        "                      \"answer\": result[\"answer\"],\n",
        "                      \"score\": result[\"score\"]\n",
        "                  }\n",
        "                  best_score = result[\"score\"]\n",
        "\n",
        "        return best_result\n",
        "\n",
        "    def chunk_text(self, text, chunk_size=3, overlap=0.5):\n",
        "        sentences = sent_tokenize(text)  # Tokenize text into sentences\n",
        "        step = int(chunk_size * (1 - overlap))  # Overlapping step\n",
        "\n",
        "        chunks = []\n",
        "        for i in range(0, len(sentences), step):\n",
        "            chunk = sentences[i:i + chunk_size]\n",
        "            if not chunk:\n",
        "                continue\n",
        "            chunks.append(\" \".join(chunk))\n",
        "\n",
        "        return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8burd_D9KK_E"
      },
      "source": [
        "# QA Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DdkmoxgOi9vo"
      },
      "outputs": [],
      "source": [
        "class QA:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path = CURRENT_MODEL,\n",
        "        tokenizer_path = CURRENT_TOKENIZER,\n",
        "        dataset = CEBQA_DATASET,\n",
        "        indexer_type = BM25,\n",
        "        index_name = INDEX_NAME,\n",
        "        k = K,\n",
        "        sample = None,\n",
        "        isRandom = False,\n",
        "        overlap = 0.0,\n",
        "        num_chunks = 1,\n",
        "        use_fine_tuned = False\n",
        "      ):\n",
        "        reader = Reader(model_path=model_path, tokenizer_path=tokenizer_path)\n",
        "\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer_path = tokenizer_path\n",
        "        self.reader = reader\n",
        "        self.tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "        test_dataset = load_dataset(dataset)[\"test\"]\n",
        "        self.dataset = test_dataset.filter(self.filter_incomplete_examples) \\\n",
        "            .map(self.normalize_row, batched=True) \\\n",
        "            .map(self.tokenize_train_function, batched=True)\\\n",
        "            .filter(self.decode_error)\n",
        "        self.sentence_transformer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.k = k\n",
        "        self.overlap = overlap\n",
        "        self.num_chunks = num_chunks\n",
        "        self.sample = sample\n",
        "        self.isRandom = isRandom\n",
        "        self.index_name = index_name\n",
        "        self.indexer_type = indexer_type\n",
        "        self.use_fine_tuned = use_fine_tuned\n",
        "\n",
        "        if sample is not None and isRandom:\n",
        "            indices = random.sample(range(len(self.dataset)), sample)\n",
        "            self.dataset = self.dataset.select(indices)\n",
        "        elif sample is not None and not isRandom:\n",
        "            self.dataset = self.dataset.select(range(sample))\n",
        "\n",
        "        print(f\"Initiating QA Pipeline.\")\n",
        "        print(f\"QA model {self.model_path}\")\n",
        "        print(f\"QA tokenizer {self.tokenizer_path}\")\n",
        "        print(f\"QA reader {self.reader}\")\n",
        "        print(f\"QA dataset {len(self.dataset)}\")\n",
        "        print(f\"QA k {self.k}\")\n",
        "        print(f\"QA overlap {self.overlap}\")\n",
        "        print(f\"QA num_chunks {self.num_chunks}\")\n",
        "        print(f\"QA sample {self.sample}\")\n",
        "        print(f\"QA isRandom {self.isRandom}\")\n",
        "        print(f\"QA index_name {self.index_name}\")\n",
        "        print(f\"QA indexer {self.index_name}\")\n",
        "        self.queries = [\n",
        "            {\n",
        "                \"id\": item['id'],\n",
        "                \"article_id\": item['article_id'],\n",
        "                \"question\": item['question'],\n",
        "                \"context\": {\n",
        "                    \"text\": item['context'],\n",
        "                    \"start\": item['context_start']\n",
        "                },\n",
        "                \"answer\": {\n",
        "                    \"text\": item['answer'],\n",
        "                    \"start\": item['answer_start']\n",
        "                }\n",
        "            }\n",
        "            for item in self.dataset\n",
        "        ]\n",
        "\n",
        "        if indexer_type == BM25:\n",
        "            self.retriever = BM25Retriever(index_name=self.index_name)\n",
        "            self.run_top_docs_batch_bm25()\n",
        "        elif indexer_type == HYBRID:\n",
        "            self.retriever = None\n",
        "            self.run_top_docs_batch_hybrid()\n",
        "        else:\n",
        "            self.retriever = FAISSRetriever(top_k=self.k, use_fine_tuned = use_fine_tuned)\n",
        "            self.run_top_docs_batch_faiss()\n",
        "        print(f\"QA retriever {self.retriever}\")\n",
        "\n",
        "\n",
        "    def run_top_docs_batch_bm25(self):\n",
        "        self.top_docs = self.retriever.retrieve_batch_query_dict(\n",
        "            queries_list = self.queries,\n",
        "            top_k=self.k\n",
        "        )\n",
        "\n",
        "        return self.top_docs\n",
        "\n",
        "    def run_top_docs_batch_faiss(self):\n",
        "        docs = []\n",
        "        for item in self.dataset:\n",
        "            result = self.retriever.retrieve(item[\"question\"])\n",
        "            doc = {\n",
        "                \"query_id\": item[\"id\"],\n",
        "                \"top_docs\": result\n",
        "            }\n",
        "            docs.append(doc)\n",
        "\n",
        "        self.top_docs = docs\n",
        "        return self.top_docs\n",
        "\n",
        "    # def run_top_docs_batch_hybrid(self):\n",
        "    #     bm25_retriever = BM25Retriever(index_name=self.index_name)\n",
        "    #     faiss_retriever = FAISSRetriever(top_k=self.k, use_fine_tuned = self.use_fine_tuned)\n",
        "\n",
        "    #     bm25_top_docs = bm25_retriever.retrieve_batch_query_dict(\n",
        "    #         queries_list = self.queries,\n",
        "    #         top_k=self.k\n",
        "    #     )\n",
        "\n",
        "    #     faiss_top_docs = []\n",
        "    #     for item in self.dataset:\n",
        "    #         result = faiss_retriever.retrieve(item[\"question\"])\n",
        "    #         doc = {\n",
        "    #             \"query_id\": item[\"id\"],\n",
        "    #             \"top_docs\": result\n",
        "    #         }\n",
        "    #         faiss_top_docs.append(doc)\n",
        "\n",
        "    #     # self.top_docs = {\n",
        "    #     #     \"bm25\": bm25_top_docs,\n",
        "    #     #     \"faiss\": faiss_top_docs\n",
        "    #     # }\n",
        "\n",
        "    #     for item in self.queries:\n",
        "    #         bm25_docs = bm25_top_docs[item[\"id\"]]\n",
        "    #         faiss_docs = faiss_top_docs[item[\"id\"]]\n",
        "\n",
        "\n",
        "    #     return self.top_docs\n",
        "\n",
        "    def run_top_docs_batch_hybrid(self):\n",
        "      \"\"\"\n",
        "      Run hybrid retrieval combining BM25 and FAISS results.\n",
        "      The final score is a weighted combination: BM25_score + (1.1 * FAISS_score).\n",
        "      \"\"\"\n",
        "      # Initialize retrievers\n",
        "      bm25_retriever = BM25Retriever(index_name=self.index_name)\n",
        "      faiss_retriever = FAISSRetriever(top_k=self.k, use_fine_tuned=self.use_fine_tuned)\n",
        "\n",
        "      # Get BM25 results\n",
        "      bm25_top_docs = bm25_retriever.retrieve_batch_query_dict(\n",
        "          queries_list=self.queries,\n",
        "          top_k=self.k\n",
        "      )\n",
        "\n",
        "      # Get FAISS results\n",
        "      faiss_top_docs = []\n",
        "      for item in self.dataset:\n",
        "          result = faiss_retriever.retrieve(item[\"question\"])\n",
        "          doc = {\n",
        "              \"query_id\": item[\"id\"],\n",
        "              \"top_docs\": result\n",
        "          }\n",
        "          faiss_top_docs.append(doc)\n",
        "\n",
        "      print(bm25_top_docs)\n",
        "      print(faiss_top_docs)\n",
        "\n",
        "      # Create a mapping from query_id to query results for easier access\n",
        "      bm25_results_map = {doc[\"query_id\"]: doc[\"top_docs\"] for doc in bm25_top_docs}\n",
        "      faiss_results_map = {doc[\"query_id\"]: doc[\"top_docs\"] for doc in faiss_top_docs}\n",
        "\n",
        "      # Combine results for each query\n",
        "      hybrid_results = []\n",
        "      query_ids = set(list(bm25_results_map.keys()) + list(faiss_results_map.keys()))\n",
        "\n",
        "      for query_id in query_ids:\n",
        "          # Get results from both retrievers for this query\n",
        "          bm25_docs = bm25_results_map.get(query_id, [])\n",
        "          faiss_docs = faiss_results_map.get(query_id, [])\n",
        "\n",
        "          # Create a mapping of doc_id to document for easy merging\n",
        "          doc_map = {}\n",
        "\n",
        "          # Process BM25 results\n",
        "          for doc in bm25_docs:\n",
        "              doc_id = doc[\"id\"]\n",
        "              doc_map[doc_id] = {\n",
        "                  \"id\": doc_id,\n",
        "                  \"title\": doc.get(\"title\", \"\"),\n",
        "                  \"body\": doc.get(\"body\", \"\"),\n",
        "                  \"bm25_score\": doc.get(\"score\", 0.0),\n",
        "                  \"faiss_score\": 0.0,\n",
        "                  \"score\": 0.0  # Will be updated with combined score\n",
        "              }\n",
        "\n",
        "          # Process FAISS results and combine scores\n",
        "          for doc in faiss_docs:\n",
        "              doc_id = doc[\"id\"]\n",
        "              if doc_id in doc_map:\n",
        "                  # Document exists in BM25 results, update FAISS score\n",
        "                  doc_map[doc_id][\"faiss_score\"] = doc.get(\"score\", 0.0)\n",
        "              else:\n",
        "                  # Document only in FAISS results, add to map\n",
        "                  doc_map[doc_id] = {\n",
        "                      \"id\": doc_id,\n",
        "                      \"title\": doc.get(\"title\", \"\"),\n",
        "                      \"body\": doc.get(\"body\", \"\"),\n",
        "                      \"bm25_score\": 0.0,\n",
        "                      \"faiss_score\": doc.get(\"score\", 0.0),\n",
        "                      \"score\": 0.0  # Will be updated with combined score\n",
        "                  }\n",
        "\n",
        "          # # Optional: Normalize scores (recommended for more balanced fusion)\n",
        "          # bm25_scores = [d[\"bm25_score\"] for d in doc_map.values() if d[\"bm25_score\"] > 0]\n",
        "          # faiss_scores = [d[\"faiss_score\"] for d in doc_map.values() if d[\"faiss_score\"] > 0]\n",
        "\n",
        "          # if bm25_scores and faiss_scores:\n",
        "          #     bm25_max = max(bm25_scores)\n",
        "          #     faiss_max = max(faiss_scores)\n",
        "\n",
        "          #     # Avoid division by zero\n",
        "          #     if bm25_max > 0 and faiss_max > 0:\n",
        "          #         for doc_id in doc_map:\n",
        "          #             if doc_map[doc_id][\"bm25_score\"] > 0:\n",
        "          #                 doc_map[doc_id][\"bm25_score\"] /= bm25_max\n",
        "          #             if doc_map[doc_id][\"faiss_score\"] > 0:\n",
        "          #                 doc_map[doc_id][\"faiss_score\"] /= faiss_max\n",
        "\n",
        "          # Calculate combined scores\n",
        "          faiss_weight = 1.1  # As specified in the requirement\n",
        "          for doc_id, doc in doc_map.items():\n",
        "              # Calculate the hybrid score: BM25 + (weight * FAISS)\n",
        "              doc[\"score\"] = doc[\"bm25_score\"] + (faiss_weight * doc[\"faiss_score\"])\n",
        "\n",
        "          # Sort by combined score and take top_k\n",
        "          combined_docs = list(doc_map.values())\n",
        "          combined_docs.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "          top_k_docs = combined_docs[:self.k]\n",
        "\n",
        "          # Clean up internal scoring fields if needed\n",
        "          for doc in top_k_docs:\n",
        "              if \"bm25_score\" in doc and \"faiss_score\" in doc:\n",
        "                  # Keep only the combined score in the final results\n",
        "                  # Uncomment the following lines if you want to remove the individual scores:\n",
        "                  # doc.pop(\"bm25_score\", None)\n",
        "                  # doc.pop(\"faiss_score\", None)\n",
        "                  pass\n",
        "\n",
        "          # Add to results\n",
        "          hybrid_results.append({\n",
        "              \"query_id\": query_id,\n",
        "              \"top_docs\": top_k_docs\n",
        "          })\n",
        "\n",
        "      self.top_docs = hybrid_results\n",
        "      return self.top_docs\n",
        "\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        date_now = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))\n",
        "        print(f\"QA run for {self.model_path} on {date_now}\")\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for index, query in enumerate(self.queries):\n",
        "          print(f\"{index} processing {query['id']}\")\n",
        "          docs = self.top_docs[index]['top_docs']\n",
        "        #   print([f\"{doc}\\n\" for doc in docs])\n",
        "          answer = self.reader.extract_answer(\n",
        "              question = query[\"question\"],\n",
        "              documents = docs,\n",
        "              num_chunks = self.num_chunks,\n",
        "              overlap= self.overlap\n",
        "          )\n",
        "        #   print(query[\"answer\"][\"text\"])\n",
        "        #   print(answer[\"answer\"])\n",
        "          result = query\n",
        "          result[\"pred\"] = answer\n",
        "          result[\"top_docs\"] = docs\n",
        "          results.append(result)\n",
        "\n",
        "        self.results = results\n",
        "\n",
        "        end_time = time.time()\n",
        "        self.stats ={\n",
        "            'run_time': end_time - start_time\n",
        "        }\n",
        "        return self.results\n",
        "\n",
        "    def normalize_row(self, examples):\n",
        "        examples[\"context\"] = [unicodedata.normalize(\"NFKC\", context) for context in examples[\"context\"]]\n",
        "\n",
        "        examples[\"article_body\"] = [unicodedata.normalize(\"NFKC\", body) for body in examples[\"article_body\"]]\n",
        "\n",
        "        examples[\"answer\"] =  [unicodedata.normalize(\"NFKC\", answer) for answer in examples[\"answer\"]]\n",
        "\n",
        "        examples[\"question\"] = [unicodedata.normalize(\"NFKC\", q) for q in examples[\"question\"]]\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        \"\"\"Lowercase and remove punctuation, articles, and extra whitespace.\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\W+', ' ', text)  # Remove punctuation and special characters\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def compute_similarity(self, text1, text2):\n",
        "        \"\"\"Compute cosine similarity between two texts using Sentence Transformers.\"\"\"\n",
        "        emb1 = self.sentence_transformer.encode(text1, convert_to_tensor=True)\n",
        "        emb2 = self.sentence_transformer.encode(text2, convert_to_tensor=True)\n",
        "        similarity = util.pytorch_cos_sim(emb1, emb2).item()  # Convert tensor to float\n",
        "        return similarity\n",
        "\n",
        "    def evaluate_batch(self):\n",
        "        pass\n",
        "\n",
        "    def evaluate_retriever(self):\n",
        "        wrong_doc = []\n",
        "        for index, query in enumerate(self.queries):\n",
        "            top_doc = self.top_docs[index][\"top_docs\"]\n",
        "            if not any(doc[\"id\"] == query[\"article_id\"] for doc in top_doc):\n",
        "                wrong_doc.append(query[\"article_id\"])\n",
        "\n",
        "        return wrong_doc\n",
        "\n",
        "    def compute_retrieval_metrics(self):\n",
        "        metrics = {\n",
        "            \"hits@1\": 0,\n",
        "            \"hits@3\": 0,\n",
        "            \"hits@5\": 0,\n",
        "            \"hits@10\": 0,\n",
        "            \"mrr\": 0.0\n",
        "        }\n",
        "\n",
        "        total = len(self.queries)\n",
        "\n",
        "        for index, query in enumerate(self.queries):\n",
        "            correct_id = query[\"article_id\"]\n",
        "            docs = self.top_docs[index][\"top_docs\"]  # Ranked list of dicts with 'id'\n",
        "\n",
        "            found = False\n",
        "\n",
        "            for rank, doc in enumerate(docs):\n",
        "                                    # rank is 0-based, so add 1\n",
        "                # print(rank, doc)\n",
        "\n",
        "                r = rank + 1\n",
        "                if doc[\"id\"] == correct_id:\n",
        "                    if r <= 1: metrics[\"hits@1\"] += 1\n",
        "                    if r <= 3: metrics[\"hits@3\"] += 1\n",
        "                    if r <= 5: metrics[\"hits@5\"] += 1\n",
        "                    if r <= 10: metrics[\"hits@10\"] += 1\n",
        "                    metrics[\"mrr\"] += 1 / r\n",
        "                    found = True\n",
        "                    break  # stop checking once found\n",
        "\n",
        "\n",
        "            if not found:\n",
        "                metrics[\"mrr\"] += 0.0  # optional, for clarity\n",
        "\n",
        "        # Average over total queries\n",
        "        for k in [\"hits@1\", \"hits@3\", \"hits@5\", \"hits@10\"]:\n",
        "            metrics[k] = metrics[k] / total\n",
        "        metrics[\"mrr\"] = metrics[\"mrr\"] / total\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def evaluate(self):\n",
        "        print(f\"QA evaluate for {len(self.results)} results on {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}\")\n",
        "        pred = [\n",
        "          {\n",
        "              'id': result['id'],  # Convert ID to string\n",
        "              'prediction_text': self.normalize_text(result['pred']['answer'])\n",
        "          }\n",
        "          for result in self.results\n",
        "        ]\n",
        "\n",
        "        ref = [\n",
        "            {\n",
        "                'id': item['id'],  # Convert ID to string\n",
        "                'answers': {\n",
        "                    'text': [self.normalize_text(item['answer']['text'])],\n",
        "                    'answer_start': [item['answer']['start']]\n",
        "                }\n",
        "            }\n",
        "            for item in self.results\n",
        "        ]\n",
        "\n",
        "        # Load SQuAD metric\n",
        "        metric = load(\"squad\")\n",
        "\n",
        "        # Compute metric\n",
        "        res = metric.compute(predictions=pred, references=ref)\n",
        "        sentence_match_scores = [\n",
        "            p['prediction_text'] in r['answers']['text'][0] for p, r in zip(pred, ref)\n",
        "        ]\n",
        "\n",
        "        # Compute average sentence match score\n",
        "        avg_sentence_match = np.mean(sentence_match_scores)\n",
        "\n",
        "        # Combine results\n",
        "        res[\"sentence_match\"] = float(avg_sentence_match ) * 100\n",
        "        print(res)\n",
        "\n",
        "        self.config = {\n",
        "            'model_path': self.model_path,\n",
        "            'tokenizer_path': self.tokenizer_path,\n",
        "            'k': self.k,\n",
        "            'sample': self.sample,\n",
        "            'isRandom': self.isRandom,\n",
        "            'overlap': self.overlap,\n",
        "            'num_chunks': self.num_chunks,\n",
        "            'indexer_type': self.indexer_type\n",
        "        }\n",
        "        self.eval_res = res\n",
        "\n",
        "        return self.eval_res, self.config, self.stats\n",
        "\n",
        "    def filter_incomplete_examples(self, example):\n",
        "        # Ensure both \"question\" and \"context\" exist and are non-empty\n",
        "        return \"question\" in example and example[\"question\"] and \\\n",
        "            \"article_body\" in example and example[\"answer\"]\n",
        "\n",
        "    def filter_by_token_length(self, example):\n",
        "        # Tokenize the concatenated question + article_body\n",
        "        tokens = self.tokenizer(example[\"question\"], example[\"article_body\"], truncation=False)\n",
        "        return len(tokens[\"input_ids\"]) <= 512\n",
        "\n",
        "    def decode_error(self, example):\n",
        "        input_ids = example[\"input_ids\"]\n",
        "        start_positions = example[\"start_positions\"]\n",
        "        end_positions = example[\"end_positions\"]\n",
        "        predict_answer_tokens = input_ids[start_positions : end_positions+1]\n",
        "        return self.tokenizer.decode(predict_answer_tokens) == example[\"answer\"]\n",
        "\n",
        "    def tokenize_train_function(self, examples):\n",
        "        article_text = [article for article in examples.get(\"article_body\", [\"\"])]\n",
        "        context_text = [context for context in examples.get(\"context\", [\"{}\"])]\n",
        "        answer_text = examples.get(\"answer\", [\"\"])\n",
        "        answer_start = examples.get(\"answer_start\", [0])\n",
        "        context_start_list = examples.get(\"context_start\", [0])\n",
        "        question_text = [q for q in examples.get(\"question\", [\"\"])]\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            question_text,\n",
        "            article_text,\n",
        "            truncation=\"only_second\",  # Truncate only the context\n",
        "            max_length=512,            # Limit input length\n",
        "            stride=128,                # Add a sliding window\n",
        "            return_overflowing_tokens=False,  # Handle long contexts\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "        # sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "        for i, offset in enumerate(offset_mapping):\n",
        "            answer = answer_text[i]\n",
        "            context = context_text[i]\n",
        "            article = article_text[i]\n",
        "            start_char = int(context_start_list[i]) + int(answer_start[i])\n",
        "            end_char = start_char + len(answer)\n",
        "\n",
        "\n",
        "            sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "            # Find the start and end of the context\n",
        "            idx = 0\n",
        "            while sequence_ids[idx] != 1:\n",
        "                idx += 1\n",
        "            context_start = idx\n",
        "            while sequence_ids[idx] == 1:\n",
        "                idx += 1\n",
        "            context_end = idx - 1\n",
        "\n",
        "            # If the answer is not fully inside the context, label is (0, 0)\n",
        "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                # Otherwise it's the start and end token positions\n",
        "                idx = context_start\n",
        "                while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                    idx += 1\n",
        "                start_positions.append(idx - 1)\n",
        "\n",
        "                idx = context_end\n",
        "                while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                    idx -= 1\n",
        "                end_positions.append(idx + 1)\n",
        "\n",
        "        inputs[\"start_positions\"] = start_positions\n",
        "        inputs[\"end_positions\"] = end_positions\n",
        "\n",
        "\n",
        "        return inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGbZ531XfzNW"
      },
      "source": [
        "# QA - BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDCqW6FbfzNW",
        "outputId": "cc1990f5-eb37-4858-dfba-670cf7110e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "[-0.42630348]\n"
          ]
        }
      ],
      "source": [
        "print(np.__version__)  # Check if NumPy is available\n",
        "print(torch.randn(1).numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJwSpyvvp_JZ",
        "outputId": "1be11049-69f3-4114-fddf-6a9cf0bf379f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating reader with model: /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating QA Pipeline.\n",
            "QA model /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n",
            "QA tokenizer /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/tokenizer\n",
            "QA reader <__main__.Reader object at 0x791895908d50>\n",
            "QA dataset 100\n",
            "QA k 10\n",
            "QA overlap 0.0\n",
            "QA num_chunks 1\n",
            "QA sample 100\n",
            "QA isRandom False\n",
            "QA index_name superbalita\n",
            "QA indexer superbalita\n",
            "Initiating retriever with index_name: superbalita\n",
            "Initiating ESIndexer superbalita\n",
            "Retrieve Batch Dict for 100 queries\n",
            "QA retriever <__main__.BM25Retriever object at 0x791840337c50>\n",
            "18\n",
            "{'hits@1': 0.63, 'hits@3': 0.73, 'hits@5': 0.76, 'hits@10': 0.82, 'mrr': 0.6933968253968255}\n"
          ]
        }
      ],
      "source": [
        "qa_bm25 = QA(\n",
        "    sample=100,\n",
        "    model_path=CURRENT_MODEL,\n",
        "    k = 10, overlap=0.0, num_chunks=1)\n",
        "qa_bm25.top_docs\n",
        "wrong = qa_bm25.evaluate_retriever()\n",
        "metrics = qa_bm25.compute_retrieval_metrics()\n",
        "print(len(wrong))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVStZCd5fzNX"
      },
      "outputs": [],
      "source": [
        "qa_bm25.run()\n",
        "qa_bm25.evaluate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXX0NTlEfzNX"
      },
      "source": [
        "# QA - FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "6303a15050e043929d878a4a23d78b13",
            "8e586ace97b14aeca8c3c52cc6be4b98",
            "2f06e02f78e84977b5c1e1245523e5c7",
            "59d8394b6d524a6c8ea7a21dac2591c3",
            "9775df5b224b4afe8f7f4fcf198639ea",
            "254d262abc3d421fba3dace6cb28b75f",
            "ac8692fb8a0944e58c2ef9745aca45cf",
            "ec37359df88d483da714539b06d3305f",
            "e03271f0f8d34a8093e4cccef9063ccc",
            "b64ba2738e8d4bed9ad64d1a98676518",
            "362dc31b40934dc7afb86cd09a7ddabe",
            "4a9a5096e0c44835b2f6bc759063ba4f",
            "af59be8147be46b0bede9152e16c26f2",
            "8f69eaeaf1ed48c986fbf676655159cd",
            "bf3e5b5d1f4c49a7b09e9de55d744c52",
            "100d27f49a5c4f9f8c8f9fe786de9b02",
            "afacc74ab6ee4a48a868c953e8c8db25",
            "9df11b4743b34fcbaee55862dfb9b969",
            "19e484552c9a43eca51fad433188627b",
            "d1e4f7c02701479a9c9b9117fe1d3aed",
            "6ec0e6c36f934248a5311bf3de6bc0f2",
            "7ceb564a8d1643979c6bd84ca353ccea",
            "2fca1c76450f409391aab5f52766fd7b",
            "1d7231bbc0fc43ddad747aa4a7fdc442",
            "6dcd083af0284c58be98f390a1e14641",
            "30c7cbc992e14773b512a8f8e1fe0ccd",
            "0ad7958424094254861bcd0af6bf466d",
            "e56c1e081f7241da8afb428976eb29c9",
            "8e7f54bb0751464582a8c8b61ba715e4",
            "1d5b9520bc9748a8986cdc572d4014c6",
            "b5f4496b1e0f4d6ea1f6e59203b206d1",
            "2dce5e2111004679bcaa378ed7aa35f0",
            "3e0c923fea294113a2106e48de1a9a8b",
            "48b6cefe217a49d6b3139e45cc57e050",
            "6bd7778222b647adab07d122f5a56f30",
            "3ae912dc4bcd49d5adb04d07e2449ee1",
            "4913105ebe1a4a159844138d9798986b",
            "8a88893ccfe4408abf4e849ee5014b00",
            "af3fb21d92cd414eaa0cd2d9253d0c97",
            "81d1624047774d369e0f9d3656030ebb",
            "b8935d4e0abb4a7fbc61bc9e5ec1da21",
            "30f6cd083b354d1493c22f0f0b6320f2",
            "b2ee4216fca347ac8a52deddfca4d4c5",
            "a81acf2cd1034effacc6f762b94e625e",
            "df820a8ea37349958eccce80e165ad0b",
            "2cf11375ecae4a0ca0d9112c8964234c",
            "412445987576486b8285c3ee589b1e5a",
            "aa992e9883f943fcaa14d8813373adce",
            "9586ef19a3184462918e81944df8b186",
            "bd0cff6fe1f2471a99f3eb4611d4a2fb",
            "71b6e3c8be55447fa10e6778caa3f58d",
            "3c6e4e6bd9d74a7f96aa55dd656a67c5",
            "fbb619439e394077baf641c1495bbfb6",
            "b5a54701fcf7487b9c8ad128cac3bce2",
            "d0dedf1fe3e04874b01edb261d72357e",
            "36dbda710d4a46a88e8340318ee22c2a",
            "72334fa3f6b346008b08317526246da4",
            "fdbfa102bcad479bb447d4542c33db1e",
            "d381c316d3604e6ab4d872f6ae4ff9c2",
            "fefea001fb4749beb5dd6fe95920d6f9",
            "9a3bd3bef9cf4e08bb9af0e4753de188",
            "f876e4d7b8244b889eef421a22bebeeb",
            "3c4d2806f1c04c8fb46de6668c3e1823",
            "e551810501084ff3a49bb6b9b7bb49e5",
            "e8ae941e3e0744d28533349fc6fabd00",
            "5c64abfa56f0473c8b824c3f5307de2c",
            "539ac996165642658491e7cbc05616f7",
            "6f3045f559e54a879f1724e1ddd630b4",
            "d2756cd8857c4d8798d6674fa71775a9",
            "7106f66b5dd547ffbfd43575836fc840",
            "6d36d8026cfb41d59403e8e3abc916f7",
            "495b5649e8f44591a3e1ff6a0293f23a",
            "70f77f2c6ba1426b909d573c621ba0ef",
            "da7d18453b6e4b3b82dbb840ca378b42",
            "96e831bd2b7e46c59e6ac0b822f3c56b",
            "0edb0e19c998433fb6fe89f10c354f61",
            "460d67de3cb341989978e26b3da73a9b"
          ]
        },
        "id": "gvuQYobqfzNX",
        "outputId": "19f978cd-9d5d-4884-c6d9-11776600c24d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating reader with model: /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/5596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6303a15050e043929d878a4a23d78b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating QA Pipeline.\n",
            "QA model /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n",
            "QA tokenizer /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/tokenizer\n",
            "QA reader <__main__.Reader object at 0x7f3219a1c5d0>\n",
            "QA dataset 1\n",
            "QA k 1\n",
            "QA overlap 0.0\n",
            "QA num_chunks 1\n",
            "QA sample 1\n",
            "QA isRandom False\n",
            "QA index_name superbalita\n",
            "QA indexer superbalita\n",
            "Initializing FAISS Retriever\n",
            "Loading DPR multilingual context encoder...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a9a5096e0c44835b2f6bc759063ba4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fca1c76450f409391aab5f52766fd7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b6cefe217a49d6b3139e45cc57e050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df820a8ea37349958eccce80e165ad0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/712M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36dbda710d4a46a88e8340318ee22c2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at voidful/dpr-ctx_encoder-bert-base-multilingual were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "539ac996165642658491e7cbc05616f7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "qa_faiss = QA(\n",
        "    sample=1,\n",
        "    model_path=CURRENT_MODEL,\n",
        "    k = 1, overlap=0.0, num_chunks=1,\n",
        "    indexer_type=FAISS,\n",
        "    use_fine_tuned=True)\n",
        "qa_faiss.top_docs\n",
        "# wrong_faiss = qa_faiss.evaluate_retriever()\n",
        "# metrics = qa_faiss.compute_retrieval_metrics()\n",
        "# print(len(wrong_faiss))\n",
        "# print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDx3-H0DfzNX"
      },
      "outputs": [],
      "source": [
        "qa_faiss.run()\n",
        "qa_faiss.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA - Hybrid"
      ],
      "metadata": {
        "id": "2ZkcPq5or487"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_hybrid = QA(\n",
        "    model_path=CURRENT_MODEL,\n",
        "    sample=100,\n",
        "    k = 10,\n",
        "\n",
        "    # sample=1,\n",
        "    # isRandom = True,\n",
        "    # k = 1,\n",
        "\n",
        "    overlap=0.0,\n",
        "    num_chunks=1,\n",
        "    indexer_type=HYBRID,\n",
        "    use_fine_tuned=True\n",
        "    )\n",
        "# qa_hybrid.top_docs\n",
        "\n",
        "wrong = qa_hybrid.evaluate_retriever()\n",
        "metrics = qa_hybrid.compute_retrieval_metrics()\n",
        "print(len(wrong))\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "qNGWe-DEPEzz",
        "outputId": "e8f9a6f5-c2c9-44c9-f533-42dfbfb45f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating reader with model: /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating QA Pipeline.\n",
            "QA model /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/model\n",
            "QA tokenizer /content/drive/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13/tokenizer\n",
            "QA reader <__main__.Reader object at 0x791895918d50>\n",
            "QA dataset 100\n",
            "QA k 10\n",
            "QA overlap 0.0\n",
            "QA num_chunks 1\n",
            "QA sample 100\n",
            "QA isRandom False\n",
            "QA index_name superbalita\n",
            "QA indexer superbalita\n",
            "Initiating retriever with index_name: superbalita\n",
            "Initiating ESIndexer superbalita\n",
            "Initializing FAISS Retriever\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DPR multilingual context encoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at voidful/dpr-ctx_encoder-bert-base-multilingual were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_hybrid.top_docs[0]"
      ],
      "metadata": {
        "id": "wbF1tLMSOVQ2",
        "outputId": "404b487e-d5f1-48a4-fa26-e1827dc7621f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_id': '00886-002',\n",
              " 'top_docs': [{'id': 886,\n",
              "   'title': 'Pagpanuktok ‘fake news’',\n",
              "   'body': 'Gihimakak sa kapulisan sa lalawigan sa Sugbo ang nikatap nga taho sa social media labot, matod pa, manuktok sa mga pultahan sa kabalayan sa bukid panahon sa kagabhion. Kining maong estorya nakapahadlok sa mga tawo sa bukid nga tungod ani nabalaka na sila sa ilang seguridad tungod kay basin sila ang sunod nga tuktokon ug dunay dautang mahitabo kanila. Tungod niini, ang Cebu Police Provincial Office (CCPO) niawhag sa publiko nga dili motuo sa maong estorya kay wala kini kamatuoran human nihimo’g imbestigasyon ang mga police station sa kalungsuran human nakadawat sa maong report. Matod ni Police Major Manu Catacutan, information officer sa CPPO, fake news ang nikatap sa social media nga nikuha og daghang shares nga nakapahadlok na sa publiko. “There is no truth news circulating on social media. . ” matod ni Catacutan. Bisan pa man niin,i si Police Lieutenant Colonel Lennon Marjo Abacay, tigpamaba ni Police Brigadier General Jorge Abad, hepe sa Police Regional Office (PRO 7), nagkanayon nga ang report nakaabot na sa ilang buhatan. Matod niya nga seryuso nila kini nga gihatagan sa pagtagad. Gani duna nay gitahasan nga mga personnel nga mosubay sa maong report. Apan iyang gibutyag nga pulos lang kini tabi-tabi, pulos lang estorya ug wala pay nidangop sa matag police station labot sa maong insidente. Giawhag sa kapulisan ang publiko nga kon dunay mamatikdan nga kadudahan sa ilang barangay ,labing maayo nga manawag dayon sa kapulisan aron mahatagan dayon nila sa dinalian nga pagtagad.',\n",
              "   'bm25_score': 15.906459,\n",
              "   'faiss_score': 0.0,\n",
              "   'score': 15.906459}]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6303a15050e043929d878a4a23d78b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e586ace97b14aeca8c3c52cc6be4b98",
              "IPY_MODEL_2f06e02f78e84977b5c1e1245523e5c7",
              "IPY_MODEL_59d8394b6d524a6c8ea7a21dac2591c3"
            ],
            "layout": "IPY_MODEL_9775df5b224b4afe8f7f4fcf198639ea"
          }
        },
        "8e586ace97b14aeca8c3c52cc6be4b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254d262abc3d421fba3dace6cb28b75f",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8692fb8a0944e58c2ef9745aca45cf",
            "value": "Filter: 100%"
          }
        },
        "2f06e02f78e84977b5c1e1245523e5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec37359df88d483da714539b06d3305f",
            "max": 5596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e03271f0f8d34a8093e4cccef9063ccc",
            "value": 5596
          }
        },
        "59d8394b6d524a6c8ea7a21dac2591c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64ba2738e8d4bed9ad64d1a98676518",
            "placeholder": "​",
            "style": "IPY_MODEL_362dc31b40934dc7afb86cd09a7ddabe",
            "value": " 5596/5596 [00:03&lt;00:00, 1759.06 examples/s]"
          }
        },
        "9775df5b224b4afe8f7f4fcf198639ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254d262abc3d421fba3dace6cb28b75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8692fb8a0944e58c2ef9745aca45cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec37359df88d483da714539b06d3305f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03271f0f8d34a8093e4cccef9063ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b64ba2738e8d4bed9ad64d1a98676518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362dc31b40934dc7afb86cd09a7ddabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a9a5096e0c44835b2f6bc759063ba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af59be8147be46b0bede9152e16c26f2",
              "IPY_MODEL_8f69eaeaf1ed48c986fbf676655159cd",
              "IPY_MODEL_bf3e5b5d1f4c49a7b09e9de55d744c52"
            ],
            "layout": "IPY_MODEL_100d27f49a5c4f9f8c8f9fe786de9b02"
          }
        },
        "af59be8147be46b0bede9152e16c26f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afacc74ab6ee4a48a868c953e8c8db25",
            "placeholder": "​",
            "style": "IPY_MODEL_9df11b4743b34fcbaee55862dfb9b969",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8f69eaeaf1ed48c986fbf676655159cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19e484552c9a43eca51fad433188627b",
            "max": 271,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e4f7c02701479a9c9b9117fe1d3aed",
            "value": 271
          }
        },
        "bf3e5b5d1f4c49a7b09e9de55d744c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec0e6c36f934248a5311bf3de6bc0f2",
            "placeholder": "​",
            "style": "IPY_MODEL_7ceb564a8d1643979c6bd84ca353ccea",
            "value": " 271/271 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "100d27f49a5c4f9f8c8f9fe786de9b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afacc74ab6ee4a48a868c953e8c8db25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df11b4743b34fcbaee55862dfb9b969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19e484552c9a43eca51fad433188627b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e4f7c02701479a9c9b9117fe1d3aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec0e6c36f934248a5311bf3de6bc0f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ceb564a8d1643979c6bd84ca353ccea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fca1c76450f409391aab5f52766fd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d7231bbc0fc43ddad747aa4a7fdc442",
              "IPY_MODEL_6dcd083af0284c58be98f390a1e14641",
              "IPY_MODEL_30c7cbc992e14773b512a8f8e1fe0ccd"
            ],
            "layout": "IPY_MODEL_0ad7958424094254861bcd0af6bf466d"
          }
        },
        "1d7231bbc0fc43ddad747aa4a7fdc442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56c1e081f7241da8afb428976eb29c9",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7f54bb0751464582a8c8b61ba715e4",
            "value": "vocab.txt: 100%"
          }
        },
        "6dcd083af0284c58be98f390a1e14641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5b9520bc9748a8986cdc572d4014c6",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5f4496b1e0f4d6ea1f6e59203b206d1",
            "value": 995526
          }
        },
        "30c7cbc992e14773b512a8f8e1fe0ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dce5e2111004679bcaa378ed7aa35f0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e0c923fea294113a2106e48de1a9a8b",
            "value": " 996k/996k [00:00&lt;00:00, 6.10MB/s]"
          }
        },
        "0ad7958424094254861bcd0af6bf466d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56c1e081f7241da8afb428976eb29c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7f54bb0751464582a8c8b61ba715e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5b9520bc9748a8986cdc572d4014c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f4496b1e0f4d6ea1f6e59203b206d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dce5e2111004679bcaa378ed7aa35f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0c923fea294113a2106e48de1a9a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b6cefe217a49d6b3139e45cc57e050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bd7778222b647adab07d122f5a56f30",
              "IPY_MODEL_3ae912dc4bcd49d5adb04d07e2449ee1",
              "IPY_MODEL_4913105ebe1a4a159844138d9798986b"
            ],
            "layout": "IPY_MODEL_8a88893ccfe4408abf4e849ee5014b00"
          }
        },
        "6bd7778222b647adab07d122f5a56f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3fb21d92cd414eaa0cd2d9253d0c97",
            "placeholder": "​",
            "style": "IPY_MODEL_81d1624047774d369e0f9d3656030ebb",
            "value": "tokenizer.json: 100%"
          }
        },
        "3ae912dc4bcd49d5adb04d07e2449ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8935d4e0abb4a7fbc61bc9e5ec1da21",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f6cd083b354d1493c22f0f0b6320f2",
            "value": 1961828
          }
        },
        "4913105ebe1a4a159844138d9798986b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ee4216fca347ac8a52deddfca4d4c5",
            "placeholder": "​",
            "style": "IPY_MODEL_a81acf2cd1034effacc6f762b94e625e",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 17.4MB/s]"
          }
        },
        "8a88893ccfe4408abf4e849ee5014b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3fb21d92cd414eaa0cd2d9253d0c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d1624047774d369e0f9d3656030ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8935d4e0abb4a7fbc61bc9e5ec1da21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f6cd083b354d1493c22f0f0b6320f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2ee4216fca347ac8a52deddfca4d4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81acf2cd1034effacc6f762b94e625e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df820a8ea37349958eccce80e165ad0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cf11375ecae4a0ca0d9112c8964234c",
              "IPY_MODEL_412445987576486b8285c3ee589b1e5a",
              "IPY_MODEL_aa992e9883f943fcaa14d8813373adce"
            ],
            "layout": "IPY_MODEL_9586ef19a3184462918e81944df8b186"
          }
        },
        "2cf11375ecae4a0ca0d9112c8964234c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0cff6fe1f2471a99f3eb4611d4a2fb",
            "placeholder": "​",
            "style": "IPY_MODEL_71b6e3c8be55447fa10e6778caa3f58d",
            "value": "config.json: 100%"
          }
        },
        "412445987576486b8285c3ee589b1e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6e4e6bd9d74a7f96aa55dd656a67c5",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbb619439e394077baf641c1495bbfb6",
            "value": 614
          }
        },
        "aa992e9883f943fcaa14d8813373adce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a54701fcf7487b9c8ad128cac3bce2",
            "placeholder": "​",
            "style": "IPY_MODEL_d0dedf1fe3e04874b01edb261d72357e",
            "value": " 614/614 [00:00&lt;00:00, 30.2kB/s]"
          }
        },
        "9586ef19a3184462918e81944df8b186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0cff6fe1f2471a99f3eb4611d4a2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b6e3c8be55447fa10e6778caa3f58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6e4e6bd9d74a7f96aa55dd656a67c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb619439e394077baf641c1495bbfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5a54701fcf7487b9c8ad128cac3bce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dedf1fe3e04874b01edb261d72357e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36dbda710d4a46a88e8340318ee22c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72334fa3f6b346008b08317526246da4",
              "IPY_MODEL_fdbfa102bcad479bb447d4542c33db1e",
              "IPY_MODEL_d381c316d3604e6ab4d872f6ae4ff9c2"
            ],
            "layout": "IPY_MODEL_fefea001fb4749beb5dd6fe95920d6f9"
          }
        },
        "72334fa3f6b346008b08317526246da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3bd3bef9cf4e08bb9af0e4753de188",
            "placeholder": "​",
            "style": "IPY_MODEL_f876e4d7b8244b889eef421a22bebeeb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fdbfa102bcad479bb447d4542c33db1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4d2806f1c04c8fb46de6668c3e1823",
            "max": 711507919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e551810501084ff3a49bb6b9b7bb49e5",
            "value": 711507919
          }
        },
        "d381c316d3604e6ab4d872f6ae4ff9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ae941e3e0744d28533349fc6fabd00",
            "placeholder": "​",
            "style": "IPY_MODEL_5c64abfa56f0473c8b824c3f5307de2c",
            "value": " 712M/712M [00:05&lt;00:00, 129MB/s]"
          }
        },
        "fefea001fb4749beb5dd6fe95920d6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3bd3bef9cf4e08bb9af0e4753de188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f876e4d7b8244b889eef421a22bebeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4d2806f1c04c8fb46de6668c3e1823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e551810501084ff3a49bb6b9b7bb49e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8ae941e3e0744d28533349fc6fabd00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c64abfa56f0473c8b824c3f5307de2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539ac996165642658491e7cbc05616f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f3045f559e54a879f1724e1ddd630b4",
              "IPY_MODEL_d2756cd8857c4d8798d6674fa71775a9",
              "IPY_MODEL_7106f66b5dd547ffbfd43575836fc840"
            ],
            "layout": "IPY_MODEL_6d36d8026cfb41d59403e8e3abc916f7"
          }
        },
        "6f3045f559e54a879f1724e1ddd630b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495b5649e8f44591a3e1ff6a0293f23a",
            "placeholder": "​",
            "style": "IPY_MODEL_70f77f2c6ba1426b909d573c621ba0ef",
            "value": "model.safetensors: 100%"
          }
        },
        "d2756cd8857c4d8798d6674fa71775a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da7d18453b6e4b3b82dbb840ca378b42",
            "max": 711444920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96e831bd2b7e46c59e6ac0b822f3c56b",
            "value": 711444920
          }
        },
        "7106f66b5dd547ffbfd43575836fc840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0edb0e19c998433fb6fe89f10c354f61",
            "placeholder": "​",
            "style": "IPY_MODEL_460d67de3cb341989978e26b3da73a9b",
            "value": " 711M/711M [00:06&lt;00:00, 96.9MB/s]"
          }
        },
        "6d36d8026cfb41d59403e8e3abc916f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495b5649e8f44591a3e1ff6a0293f23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f77f2c6ba1426b909d573c621ba0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da7d18453b6e4b3b82dbb840ca378b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e831bd2b7e46c59e6ac0b822f3c56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0edb0e19c998433fb6fe89f10c354f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460d67de3cb341989978e26b3da73a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}