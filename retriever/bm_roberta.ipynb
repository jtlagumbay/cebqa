{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtlagumbay/cebqa/blob/main/retriever/bm_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otq_L0hL6e2P"
      },
      "source": [
        "# **QA Pipeline**\n",
        "\n",
        "1. ElasticSeach Indexer\n",
        "2. BM25 Retriever\n",
        "3. Fine-tuned XLMR Reader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOvUOWAOgjQj"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPzhJswwfHQZ"
      },
      "outputs": [],
      "source": [
        "pip install elasticsearch transformers datasets evaluate rank_bm25 nltk fuzzywuzzy sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kOoiI65fzNT"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade --no-cache-dir numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd5lCHKLfzNT"
      },
      "outputs": [],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2596jflKFZi"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppd3LkTdLVbR"
      },
      "outputs": [],
      "source": [
        "CEBQA_DATASET = \"jhoannarica/cebquad_split\"\n",
        "# ELASTIC_URL = \"https://tender-separately-mudfish.ngrok-free.app\"\n",
        "# CURRENT_MODEL = \"/content/drive/MyDrive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/xlmr/2025-03-15_09-36/model\"\n",
        "# CURRENT_TOKENIZER = \"/content/drive/MyDrive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/xlmr/2025-03-15_09-36/tokenizer\"\n",
        "CURRENT_ROOT = \"/Users/jhoannaricalagumbay/Library/CloudStorage/GoogleDrive-jtlagumbay@up.edu.ph/My Drive/UP Files/IV - 2nd sem/CMSC 198.1/cebqa_roberta/new-split/xlmr_body-filtered/2025-04-04_05-13\"\n",
        "CURRENT_MODEL = CURRENT_ROOT+\"/model\"\n",
        "CURRENT_TOKENIZER = CURRENT_ROOT+\"/tokenizer\"\n",
        "ELASTIC_URL = \"http://localhost:9200\"\n",
        "INDEX_NAME = \"superbalita\"\n",
        "K = 3\n",
        "DATASET_CSV = \"/Users/jhoannaricalagumbay/School/cebqa/dataset/articles_202503120405_author_removed_fixed.csv\"\n",
        "BM25 = \"bm25\"\n",
        "FAISS = \"faiss\"\n",
        "CEBQA_DPR_MODEL = \"/Users/jhoannaricalagumbay/Library/CloudStorage/GoogleDrive-jtlagumbay@up.edu.ph/My Drive/cebqa/dpr/2025-04-16_03-37/model\"\n",
        "CEBQA_DPR_TOKENIZER = \"/Users/jhoannaricalagumbay/Library/CloudStorage/GoogleDrive-jtlagumbay@up.edu.ph/My Drive/cebqa/dpr/2025-04-16_03-37/tokenizer\"\n",
        "DPR_CONTEXT_ENCODER = \"voidful/dpr-ctx_encoder-bert-base-multilingual\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8h9VpP0gnfK"
      },
      "source": [
        "# Indexer\n",
        "\n",
        "Start ElasticSearch Locally:\n",
        "1. Start ES docker\n",
        "2. Start NGROK: `ngrok http --url=tender-separately-mudfish.ngrok-free.app 9200`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXMwFDbHvpi7"
      },
      "outputs": [],
      "source": [
        "headers = {\n",
        "    \"Origin\": \"https://colab.research.google.com\",\n",
        "     \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "response = requests.options(ELASTIC_URL, headers=headers)\n",
        "print(response.headers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCzdjxWMGbQI"
      },
      "outputs": [],
      "source": [
        "es = Elasticsearch([ELASTIC_URL], verify_certs=False, headers=headers)\n",
        "print(es.info())\n",
        "# try:\n",
        "#     print(es.transport.perform_request('GET', '/'))\n",
        "# except Exception as e:\n",
        "#     print(\"Error:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IACpNh6CgpD7"
      },
      "outputs": [],
      "source": [
        "class ElasticSearchIndexer:\n",
        "    def __init__(self, index_name=INDEX_NAME):\n",
        "        self.index_name = index_name\n",
        "        self.es = Elasticsearch(ELASTIC_URL)  # Ensure ES is running\n",
        "        print(f\"Initiating ESIndexer {self.index_name}\")\n",
        "\n",
        "    def create_index(self):\n",
        "        \"\"\" Create an index with a text field for BM25 \"\"\"\n",
        "        if not self.es.indices.exists(index=self.index_name):\n",
        "            self.es.indices.create(index=self.index_name, body={\n",
        "                \"settings\": {\n",
        "                    \"number_of_shards\": 1,\n",
        "                    \"number_of_replicas\": 0\n",
        "                },\n",
        "                \"mappings\": {\n",
        "                    \"properties\": {\n",
        "                        \"id\": {\"type\": \"keyword\"},\n",
        "                        \"title\": {\"type\": \"text\"},\n",
        "                        \"body\": {\"type\": \"text\"}\n",
        "                    }\n",
        "                }\n",
        "            })\n",
        "            print(f\"Index '{self.index_name}' created.\")\n",
        "\n",
        "    def index_documents(self, documents):\n",
        "        \"\"\" Bulk index documents into ElasticSearch \"\"\"\n",
        "        actions = [\n",
        "            {\n",
        "                \"_index\": self.index_name,\n",
        "                \"_id\": doc[\"id\"],  # Use document ID for uniqueness\n",
        "                \"_source\": {\n",
        "                    \"id\": doc[\"id\"],\n",
        "                    \"title\": doc[\"pseudonymized_title\"],\n",
        "                    \"body\": doc[\"pseudonymized_body\"]\n",
        "                }\n",
        "            }\n",
        "            for doc in documents\n",
        "        ]\n",
        "        bulk(self.es, actions)\n",
        "        print(f\"Indexed {len(documents)} documents.\")\n",
        "\n",
        "    def index_from_csv(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        documents = df.to_dict(orient=\"records\")  # Convert DataFrame to a list of dicts\n",
        "        self.index_documents(documents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNaD93tOiGnj"
      },
      "outputs": [],
      "source": [
        "# Sample usage\n",
        "# indexer = ElasticSearchIndexer()\n",
        "# indexer.create_index()\n",
        "# indexer.index_from_csv(\"/Users/jhoannaricalagumbay/School/cebqa/dataset/articles_202503120405_author_removed_fixed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjVIRDtt2Kjh"
      },
      "source": [
        "# BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWU0iGhM2Mr5"
      },
      "outputs": [],
      "source": [
        "class BM25Retriever:\n",
        "    def __init__(self, index_name=\"superbalita\"):\n",
        "        print(f\"Initiating retriever with index_name: {index_name}\")\n",
        "        self.index_name = index_name\n",
        "        self.es = Elasticsearch(ELASTIC_URL)\n",
        "\n",
        "    def retrieve(self, query, top_k=3):\n",
        "        \"\"\" Retrieve top-k relevant documents using BM25 \"\"\"\n",
        "        print(f\"retrieving {top_k} docs for [{query}]\")\n",
        "        response = self.es.search(index=self.index_name, body={\n",
        "            \"query\": {\n",
        "                \"match\": {\n",
        "                    \"body\": query\n",
        "                }\n",
        "            },\n",
        "            \"size\": top_k\n",
        "        })\n",
        "        return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n",
        "\n",
        "    def retrieve_batch(self, queries, top_k=3):\n",
        "        print(f\"Retrieve Batch for {len(queries)} queries\")\n",
        "        \"\"\" Retrieve top-k relevant documents for multiple queries using BM25 in batch mode \"\"\"\n",
        "        if not isinstance(queries, list):\n",
        "            raise ValueError(\"queries should be a list of strings\")\n",
        "\n",
        "        # Multi-search request body\n",
        "        request_body = \"\"\n",
        "        for query in queries:\n",
        "            safe_question = json.dumps(query)\n",
        "            request_body += f'{{\"index\": \"{self.index_name}\"}}\\n'  # Metadata\n",
        "            request_body += f'{{\"query\": {{\"match\": {{\"body\": {safe_question}}}}}, \"size\": {top_k}}}\\n'  # Query\n",
        "\n",
        "        # Send multi-search request\n",
        "        response = self.es.msearch(body=request_body)\n",
        "\n",
        "        # Extract results\n",
        "        results = []\n",
        "        for query_response in response[\"responses\"]:\n",
        "            retrieved_docs = [hit[\"_source\"] for hit in query_response[\"hits\"][\"hits\"]]\n",
        "            results.append(retrieved_docs)\n",
        "\n",
        "        return results  # List of lists, where each sublist contains retrieved documents for a query\n",
        "\n",
        "    def retrieve_batch_query_dict(self, queries_list, top_k=3):\n",
        "        print(f\"Retrieve Batch Dict for {len(queries_list)} queries\")\n",
        "\n",
        "        \"\"\" Retrieve top-k relevant documents for multiple queries using BM25 in batch mode.\n",
        "\n",
        "        Args:\n",
        "            queries_list (list): A list of dictionaries, each containing 'id' and 'question'.\n",
        "            top_k (int): Number of top relevant documents to retrieve per query.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary where keys are query IDs and values are lists of retrieved documents.\n",
        "        \"\"\"\n",
        "        if not isinstance(queries_list, list) or not all(isinstance(q, dict) and 'id' in q and 'question' in q for q in queries_list):\n",
        "            raise ValueError(\"queries_list should be a list of dictionaries with 'id' and 'question' keys\")\n",
        "\n",
        "        # Multi-search request body\n",
        "        request_body = \"\"\n",
        "        query_ids = []  # To track IDs in order\n",
        "        for query in queries_list:\n",
        "            safe_question = json.dumps(query[\"question\"])\n",
        "            query_ids.append(query[\"id\"])\n",
        "            request_body += f'{{\"index\": \"{self.index_name}\"}}\\n'  # Metadata\n",
        "            request_body += f'{{\"query\": {{\"match\": {{\"body\": {safe_question}}}}}, \"size\": {top_k}}}\\n'  # Query\n",
        "\n",
        "        # Send multi-search request\n",
        "        response = self.es.msearch(body=request_body)\n",
        "\n",
        "        # Extract results and associate with query IDs\n",
        "        results = []\n",
        "        for i, query_response in enumerate(response[\"responses\"]):\n",
        "            retrieved_docs = [hit[\"_source\"] for hit in query_response[\"hits\"][\"hits\"]]\n",
        "            results.append({\n",
        "                \"query_id\": str(query_ids[i]),\n",
        "                \"top_docs\": retrieved_docs\n",
        "            })\n",
        "\n",
        "        return results  # Dictionary format: {id: retrieved_docs}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsSSqnQt2rxX"
      },
      "outputs": [],
      "source": [
        "# Sample usage\n",
        "retriever = BM25Retriever()\n",
        "query = ['Unsa ang giingon ni Gobernador Abalayan nga mabuhat ra \"with a united country\"?']\n",
        "top_docs = retriever.retrieve_batch(query)\n",
        "print(\"Retrieved Documents:\", top_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACSdoCoTfzNV"
      },
      "source": [
        "# FAISS Indexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emJXIlwMfzNV"
      },
      "outputs": [],
      "source": [
        "class FAISSIndexer:\n",
        "    def __init__(self, index_file=\"faiss_index.idx\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", use_fine_tuned = False):\n",
        "        self.index_file = index_file\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(\"Loading DPR multilingual context encoder...\")\n",
        "        self.dpr_tokenizer = DPRContextEncoderTokenizer.from_pretrained(DPR_CONTEXT_ENCODER)\n",
        "        self.dpr_model = DPRContextEncoder.from_pretrained(DPR_CONTEXT_ENCODER)\n",
        "        self.use_fine_tuned = use_fine_tuned\n",
        "        self.index = None\n",
        "        self.documents = []  # Store original text\n",
        "        self.index_from_csv()\n",
        "        print(\"FAISS Indexer initialized.\")\n",
        "\n",
        "\n",
        "    def encode_contexts_with_dpr(self):\n",
        "        \"\"\"Encode contexts using DPR multilingual context encoder and re-index.\"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.dpr_model.to(device)\n",
        "        self.dpr_model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = self.dpr_tokenizer(\n",
        "                self.documents,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=512\n",
        "            ).to(device)\n",
        "\n",
        "            embeddings = self.dpr_model(**inputs).pooler_output.cpu().numpy()\n",
        "\n",
        "            if not embeddings.flags['C_CONTIGUOUS']:\n",
        "                embeddings = np.ascontiguousarray(embeddings)\n",
        "\n",
        "            faiss.normalize_L2(embeddings)\n",
        "            return embeddings\n",
        "\n",
        "    def create_index(self, d):\n",
        "        \"\"\"Create a new FAISS index.\"\"\"\n",
        "        self.index = faiss.IndexFlatL2(d)\n",
        "        print(f\"Created FAISS index with dimension {d}.\")\n",
        "\n",
        "    def index_documents(self, documents):\n",
        "        \"\"\"Index documents into FAISS.\"\"\"\n",
        "        self.documents = [doc['pseudonymized_body'] for doc in documents]\n",
        "        self.article_ids = [doc['id'] for doc in documents]\n",
        "        self.titles = [doc['pseudonymized_title'] for doc in documents]\n",
        "\n",
        "        if self.use_fine_tuned:\n",
        "            embeddings = self.encode_contexts_with_dpr()\n",
        "        else:\n",
        "            embeddings = self.model.encode(self.documents, convert_to_numpy=True)\n",
        "\n",
        "        d = embeddings.shape[1]\n",
        "\n",
        "        if self.index is None:\n",
        "            self.create_index(d)\n",
        "\n",
        "        self.index.add(embeddings)\n",
        "        print(f\"Indexed {len(documents)} documents into FAISS.\")\n",
        "        self.save_index()\n",
        "\n",
        "    def index_from_csv(self, file_path=DATASET_CSV):\n",
        "        \"\"\"Load documents from a CSV file and index them.\"\"\"\n",
        "        df = pd.read_csv(file_path)\n",
        "        documents = df.to_dict(orient=\"records\")\n",
        "        self.index_documents(documents)\n",
        "\n",
        "    def save_index(self):\n",
        "        \"\"\"Save FAISS index to disk.\"\"\"\n",
        "        faiss.write_index(self.index, self.index_file)\n",
        "        print(f\"FAISS index saved to {self.index_file}.\")\n",
        "\n",
        "    def load_index(self):\n",
        "        \"\"\"Load FAISS index from disk.\"\"\"\n",
        "        self.index = faiss.read_index(self.index_file)\n",
        "        print(f\"FAISS index loaded from {self.index_file}.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0jb0opFfzNV"
      },
      "outputs": [],
      "source": [
        "class FAISSRetriever:\n",
        "    def __init__(\n",
        "            self,\n",
        "            q_encoder = DPRQuestionEncoder.from_pretrained(CEBQA_DPR_MODEL),\n",
        "            q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(CEBQA_DPR_TOKENIZER),\n",
        "            index_file=\"faiss_index.idx\",\n",
        "            top_k=3,\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "            use_fine_tuned = False\n",
        "        ):\n",
        "        print(\"Initializing FAISS Retriever\")\n",
        "        self.indexer = FAISSIndexer(index_file=index_file, use_fine_tuned=use_fine_tuned)\n",
        "        self.top_k = top_k\n",
        "        self.use_fine_tuned = use_fine_tuned\n",
        "        self.q_encoder = q_encoder\n",
        "        self.q_tokenizer = q_tokenizer\n",
        "        self.device = device\n",
        "\n",
        "        # Move model to the appropriate device\n",
        "        self.q_encoder.to(device)\n",
        "        self.q_encoder.eval()\n",
        "\n",
        "    def encode_query(self, query):\n",
        "        \"\"\"Encode the query using the fine-tuned question encoder.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            inputs = self.q_tokenizer(\n",
        "                query,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=64\n",
        "            ).to(self.device)\n",
        "\n",
        "            embeddings = self.q_encoder(**inputs).pooler_output.cpu().numpy()\n",
        "\n",
        "            # Ensure embeddings are C-contiguous for FAISS\n",
        "            if not embeddings.flags['C_CONTIGUOUS']:\n",
        "                embeddings = np.ascontiguousarray(embeddings)\n",
        "\n",
        "            # Normalize embeddings for cosine similarity\n",
        "            faiss.normalize_L2(embeddings)\n",
        "\n",
        "            return embeddings\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        \"\"\"Retrieve top-k relevant documents using FAISS.\"\"\"\n",
        "        if self.use_fine_tuned:\n",
        "            query_embedding = self.encode_query([query])\n",
        "        else:\n",
        "            query_embedding = self.indexer.model.encode([query], convert_to_numpy=True)\n",
        "\n",
        "        D, I = self.indexer.index.search(query_embedding, self.top_k)\n",
        "        print(D, I)\n",
        "        results = [\n",
        "            {\n",
        "                \"rank\": rank + 1,\n",
        "                \"score\": float(D[0][rank]),\n",
        "                \"id\": self.indexer.article_ids[idx],\n",
        "                \"title\": self.indexer.titles[idx],\n",
        "                \"body\": self.indexer.documents[idx],\n",
        "            }\n",
        "            for rank, idx in enumerate(I[0]) if idx < len(self.indexer.documents)\n",
        "        ]\n",
        "        return results\n",
        "\n",
        "    def retrieve_batch(self, queries):\n",
        "\n",
        "        print(f\"processing {len(queries)}\")\n",
        "        \"\"\"Retrieve top-k relevant documents for multiple queries.\"\"\"\n",
        "        questions = [query[\"question\"] for query in queries]\n",
        "        if self.use_fine_tuned:\n",
        "            query_embeddings = self.encode_query([query])\n",
        "        else:\n",
        "            query_embeddings = self.indexer.model.encode(questions, convert_to_numpy=True)\n",
        "        D, I = self.indexer.index.search(query_embeddings, self.top_k)\n",
        "        print(f\"done {len(D)}\")\n",
        "        results = []\n",
        "        for query_idx, query in enumerate(queries):\n",
        "            print(f\"query idx: {query_idx}\")\n",
        "            retrieved_docs = [\n",
        "                {\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"score\": float(D[query_idx][rank]),\n",
        "                    \"text\": self.indexer.documents[idx]\n",
        "                }\n",
        "                for rank, idx in enumerate(I[query_idx]) if idx < len(self.indexer.documents)\n",
        "            ]\n",
        "            results.append({\"query\": query, \"top_docs\": retrieved_docs})\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhQrz7eDfzNV"
      },
      "outputs": [],
      "source": [
        "# # Initialize the FAISS indexer\n",
        "# indexer = FAISSIndexer(index_file=\"faiss_index.idx\")\n",
        "\n",
        "# Index documents from a CSV file\n",
        "# # Save the FAISS index for later use\n",
        "# indexer.save_index()\n",
        "\n",
        "# indexer = FAISSIndexer(index_file=\"faiss_index.idx\")\n",
        "# indexer.load_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnZAxJ11fzNW"
      },
      "outputs": [],
      "source": [
        "# Initialize the retriever with the loaded indexer\n",
        "# retriever = FAISSRetriever(index_file=\"faiss_index.idx\", top_k=K)\n",
        "\n",
        "# # Retrieve relevant documents for a single query\n",
        "# query = \"kanus-a ang palarong pambansa??\"\n",
        "# results = retriever.retrieve(query)\n",
        "\n",
        "# # Print retrieved documents\n",
        "# print(results)\n",
        "\n",
        "\n",
        "# Retrieve relevant documents for a single query\n",
        "# query = [{\"question\": \"kanus-a ang palarong pambansa?\"}, {\"question\":\"Kinsa ang hepe sa Cebu Police?\"}]\n",
        "# results = retriever.retrieve_batch(query)\n",
        "\n",
        "# # Print retrieved documents\n",
        "# for res in results:\n",
        "#     print(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwo3IpR3--n"
      },
      "source": [
        "# Reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAb9aRYL4AYY"
      },
      "outputs": [],
      "source": [
        "class Reader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path = CURRENT_MODEL,\n",
        "        tokenizer_path = CURRENT_TOKENIZER\n",
        "      ):\n",
        "        print(f\"Initiating reader with model: {model_path}\")\n",
        "        model_best = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "        tokenizer_best = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "        device = torch.device(\"mps\")\n",
        "        self.qa_pipeline = pipeline(\n",
        "            \"question-answering\",\n",
        "            model=model_best,\n",
        "            tokenizer=tokenizer_best,\n",
        "            device=device\n",
        "            )\n",
        "\n",
        "    def extract_answer_batch(self, queries_list, top_docs):\n",
        "        print(f\"Extracting batch answer for {len(queries_list)} queries\")\n",
        "        qa_dataset = Dataset.from_dict({\n",
        "          \"question\": [queries_list[\"question\"] for doc in top_docs['top_docs']] ,\n",
        "          \"context\": [doc['body'] for doc in top_docs['top_docs']]\n",
        "        })\n",
        "\n",
        "        return self.qa_pipeline(qa_dataset)\n",
        "\n",
        "    def extract_answer(self, question, documents, num_chunks = 1, overlap = 0.3):\n",
        "        print(f\"extracting answer for {question}\")\n",
        "        \"\"\" Find the best answer from retrieved documents while keeping metadata \"\"\"\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for doc in documents:\n",
        "            if num_chunks == 1:\n",
        "                contexts = [doc[\"body\"]]\n",
        "            else:\n",
        "                contexts = self.chunk_text(doc[\"body\"],  num_chunks, overlap)\n",
        "\n",
        "            for context in contexts:\n",
        "            #   print(question)\n",
        "            #   print(context)\n",
        "              result = self.qa_pipeline(question=question, context = context)\n",
        "              if result[\"score\"] > best_score:\n",
        "                  best_result = {\n",
        "                      \"article_id\": doc[\"id\"],\n",
        "                      \"title\": doc[\"title\"],\n",
        "                      \"body\": doc[\"body\"],\n",
        "                      \"answer\": result[\"answer\"],\n",
        "                      \"score\": result[\"score\"]\n",
        "                  }\n",
        "                  best_score = result[\"score\"]\n",
        "\n",
        "        return best_result\n",
        "\n",
        "    def chunk_text(self, text, chunk_size=3, overlap=0.5):\n",
        "        sentences = sent_tokenize(text)  # Tokenize text into sentences\n",
        "        step = int(chunk_size * (1 - overlap))  # Overlapping step\n",
        "\n",
        "        chunks = []\n",
        "        for i in range(0, len(sentences), step):\n",
        "            chunk = sentences[i:i + chunk_size]\n",
        "            if not chunk:\n",
        "                continue\n",
        "            chunks.append(\" \".join(chunk))\n",
        "\n",
        "        return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8burd_D9KK_E"
      },
      "source": [
        "# QA Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdkmoxgOi9vo"
      },
      "outputs": [],
      "source": [
        "class QA:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path = CURRENT_MODEL,\n",
        "        tokenizer_path = CURRENT_TOKENIZER,\n",
        "        dataset = CEBQA_DATASET,\n",
        "        indexer_type = BM25,\n",
        "        index_name = INDEX_NAME,\n",
        "        k = K,\n",
        "        sample = None,\n",
        "        isRandom = False,\n",
        "        overlap = 0.0,\n",
        "        num_chunks = 1,\n",
        "        use_fine_tuned = False\n",
        "      ):\n",
        "        reader = Reader(model_path=model_path, tokenizer_path=tokenizer_path)\n",
        "\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer_path = tokenizer_path\n",
        "        self.reader = reader\n",
        "        self.tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "        test_dataset = load_dataset(dataset)[\"test\"]\n",
        "        self.dataset = test_dataset.filter(self.filter_incomplete_examples) \\\n",
        "            .map(self.normalize_row, batched=True) \\\n",
        "            .map(self.tokenize_train_function, batched=True)\\\n",
        "            .filter(self.decode_error)\n",
        "        self.sentence_transformer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.k = k\n",
        "        self.overlap = overlap\n",
        "        self.num_chunks = num_chunks\n",
        "        self.sample = sample\n",
        "        self.isRandom = isRandom\n",
        "        self.index_name = index_name\n",
        "        self.indexer_type = indexer_type\n",
        "\n",
        "        if sample is not None and isRandom:\n",
        "            indices = random.sample(range(len(self.dataset)), sample)\n",
        "            self.dataset = self.dataset.select(indices)\n",
        "        elif sample is not None and not isRandom:\n",
        "            self.dataset = self.dataset.select(range(sample))\n",
        "\n",
        "        print(f\"Initiating QA Pipeline.\")\n",
        "        print(f\"QA model {self.model_path}\")\n",
        "        print(f\"QA tokenizer {self.tokenizer_path}\")\n",
        "        print(f\"QA reader {self.reader}\")\n",
        "        print(f\"QA dataset {len(self.dataset)}\")\n",
        "        print(f\"QA k {self.k}\")\n",
        "        print(f\"QA overlap {self.overlap}\")\n",
        "        print(f\"QA num_chunks {self.num_chunks}\")\n",
        "        print(f\"QA sample {self.sample}\")\n",
        "        print(f\"QA isRandom {self.isRandom}\")\n",
        "        print(f\"QA index_name {self.index_name}\")\n",
        "        print(f\"QA indexer {self.index_name}\")\n",
        "        self.queries = [\n",
        "            {\n",
        "                \"id\": item['id'],\n",
        "                \"article_id\": item['article_id'],\n",
        "                \"question\": item['question'],\n",
        "                \"context\": {\n",
        "                    \"text\": item['context'],\n",
        "                    \"start\": item['context_start']\n",
        "                },\n",
        "                \"answer\": {\n",
        "                    \"text\": item['answer'],\n",
        "                    \"start\": item['answer_start']\n",
        "                }\n",
        "            }\n",
        "            for item in self.dataset\n",
        "        ]\n",
        "\n",
        "        if indexer_type == BM25:\n",
        "            self.retriever = BM25Retriever(index_name=index_name)\n",
        "            self.run_top_docs_batch_bm25()\n",
        "        else:\n",
        "            self.retriever = FAISSRetriever(top_k=self.k, use_fine_tuned = use_fine_tuned)\n",
        "            self.run_top_docs_batch_faiss()\n",
        "        print(f\"QA retriever {self.retriever}\")\n",
        "\n",
        "\n",
        "    def run_top_docs_batch_bm25(self):\n",
        "        self.top_docs = self.retriever.retrieve_batch_query_dict(\n",
        "            queries_list = self.queries,\n",
        "            top_k=self.k\n",
        "        )\n",
        "\n",
        "        return self.top_docs\n",
        "\n",
        "    def run_top_docs_batch_faiss(self):\n",
        "        docs = []\n",
        "        for item in self.dataset:\n",
        "            result = self.retriever.retrieve(item[\"question\"])\n",
        "            doc = {\n",
        "                \"query_id\": item[\"id\"],\n",
        "                \"top_docs\": result\n",
        "            }\n",
        "            docs.append(doc)\n",
        "\n",
        "        self.top_docs = docs\n",
        "        return self.top_docs\n",
        "\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        date_now = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))\n",
        "        print(f\"QA run for {self.model_path} on {date_now}\")\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for index, query in enumerate(self.queries):\n",
        "          print(f\"{index} processing {query['id']}\")\n",
        "          docs = self.top_docs[index]['top_docs']\n",
        "        #   print([f\"{doc}\\n\" for doc in docs])\n",
        "          answer = self.reader.extract_answer(\n",
        "              question = query[\"question\"],\n",
        "              documents = docs,\n",
        "              num_chunks = self.num_chunks,\n",
        "              overlap= self.overlap\n",
        "          )\n",
        "        #   print(query[\"answer\"][\"text\"])\n",
        "        #   print(answer[\"answer\"])\n",
        "          result = query\n",
        "          result[\"pred\"] = answer\n",
        "          result[\"top_docs\"] = docs\n",
        "          results.append(result)\n",
        "\n",
        "        self.results = results\n",
        "\n",
        "        end_time = time.time()\n",
        "        self.stats ={\n",
        "            'run_time': end_time - start_time\n",
        "        }\n",
        "        return self.results\n",
        "\n",
        "    def normalize_row(self, examples):\n",
        "        examples[\"context\"] = [unicodedata.normalize(\"NFKC\", context) for context in examples[\"context\"]]\n",
        "\n",
        "        examples[\"article_body\"] = [unicodedata.normalize(\"NFKC\", body) for body in examples[\"article_body\"]]\n",
        "\n",
        "        examples[\"answer\"] =  [unicodedata.normalize(\"NFKC\", answer) for answer in examples[\"answer\"]]\n",
        "\n",
        "        examples[\"question\"] = [unicodedata.normalize(\"NFKC\", q) for q in examples[\"question\"]]\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        \"\"\"Lowercase and remove punctuation, articles, and extra whitespace.\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\W+', ' ', text)  # Remove punctuation and special characters\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def compute_similarity(self, text1, text2):\n",
        "        \"\"\"Compute cosine similarity between two texts using Sentence Transformers.\"\"\"\n",
        "        emb1 = self.sentence_transformer.encode(text1, convert_to_tensor=True)\n",
        "        emb2 = self.sentence_transformer.encode(text2, convert_to_tensor=True)\n",
        "        similarity = util.pytorch_cos_sim(emb1, emb2).item()  # Convert tensor to float\n",
        "        return similarity\n",
        "\n",
        "    def evaluate_batch(self):\n",
        "        pass\n",
        "\n",
        "    def evaluate_retriever(self):\n",
        "        wrong_doc = []\n",
        "        for index, query in enumerate(self.queries):\n",
        "            top_doc = self.top_docs[index][\"top_docs\"]\n",
        "            if not any(doc[\"id\"] == query[\"article_id\"] for doc in top_doc):\n",
        "                wrong_doc.append(query[\"article_id\"])\n",
        "\n",
        "        return wrong_doc\n",
        "\n",
        "    def compute_retrieval_metrics(self):\n",
        "        metrics = {\n",
        "            \"hits@1\": 0,\n",
        "            \"hits@3\": 0,\n",
        "            \"hits@5\": 0,\n",
        "            \"hits@10\": 0,\n",
        "            \"hits@50\": 0,\n",
        "            \"hits@100\": 0,\n",
        "            \"mrr\": 0.0\n",
        "        }\n",
        "\n",
        "        total = len(self.queries)\n",
        "\n",
        "        for index, query in enumerate(self.queries):\n",
        "            correct_id = query[\"article_id\"]\n",
        "            docs = self.top_docs[index][\"top_docs\"]  # Ranked list of dicts with 'id'\n",
        "\n",
        "            found = False\n",
        "            for rank, doc in enumerate(docs):\n",
        "                                    # rank is 0-based, so add 1\n",
        "                print(rank, doc)\n",
        "\n",
        "                r = rank + 1\n",
        "                if doc[\"id\"] == correct_id:\n",
        "\n",
        "                    if r <= 1: metrics[\"hits@1\"] += 1\n",
        "                    if r <= 3: metrics[\"hits@3\"] += 1\n",
        "                    if r <= 5: metrics[\"hits@5\"] += 1\n",
        "                    if r <= 10: metrics[\"hits@10\"] += 1\n",
        "                    if r <= 50: metrics[\"hits@50\"] += 1\n",
        "                    if r <= 100: metrics[\"hits@100\"] += 1\n",
        "\n",
        "                    metrics[\"mrr\"] += 1 / r\n",
        "                    found = True\n",
        "                    break  # stop checking once found\n",
        "\n",
        "            if not found:\n",
        "                metrics[\"mrr\"] += 0.0  # optional, for clarity\n",
        "\n",
        "        # Average over total queries\n",
        "        for k in [\"hits@1\", \"hits@3\", \"hits@5\", \"hits@10\", \"hits@50\", \"hits@100\"]:\n",
        "            metrics[k] = metrics[k] / total\n",
        "        metrics[\"mrr\"] = metrics[\"mrr\"] / total\n",
        "\n",
        "        return metrics\n",
        "    def evaluate(self):\n",
        "        print(f\"QA evaluate for {len(self.results)} results on {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}\")\n",
        "        pred = [\n",
        "          {\n",
        "              'id': result['id'],  # Convert ID to string\n",
        "              'prediction_text': self.normalize_text(result['pred']['answer'])\n",
        "          }\n",
        "          for result in self.results\n",
        "        ]\n",
        "\n",
        "        ref = [\n",
        "            {\n",
        "                'id': item['id'],  # Convert ID to string\n",
        "                'answers': {\n",
        "                    'text': [self.normalize_text(item['answer']['text'])],\n",
        "                    'answer_start': [item['answer']['start']]\n",
        "                }\n",
        "            }\n",
        "            for item in self.results\n",
        "        ]\n",
        "\n",
        "        # Load SQuAD metric\n",
        "        metric = load(\"squad\")\n",
        "\n",
        "        # Compute metric\n",
        "        res = metric.compute(predictions=pred, references=ref)\n",
        "        sentence_match_scores = [\n",
        "            p['prediction_text'] in r['answers']['text'][0] for p, r in zip(pred, ref)\n",
        "        ]\n",
        "\n",
        "        # Compute average sentence match score\n",
        "        avg_sentence_match = np.mean(sentence_match_scores)\n",
        "\n",
        "        # Combine results\n",
        "        res[\"sentence_match\"] = float(avg_sentence_match ) * 100\n",
        "        print(res)\n",
        "\n",
        "        self.config = {\n",
        "            'model_path': self.model_path,\n",
        "            'tokenizer_path': self.tokenizer_path,\n",
        "            'k': self.k,\n",
        "            'sample': self.sample,\n",
        "            'isRandom': self.isRandom,\n",
        "            'overlap': self.overlap,\n",
        "            'num_chunks': self.num_chunks,\n",
        "            'indexer_type': self.indexer_type\n",
        "        }\n",
        "        self.eval_res = res\n",
        "\n",
        "        return self.eval_res, self.config, self.stats\n",
        "\n",
        "    def filter_incomplete_examples(self, example):\n",
        "        # Ensure both \"question\" and \"context\" exist and are non-empty\n",
        "        return \"question\" in example and example[\"question\"] and \\\n",
        "            \"article_body\" in example and example[\"answer\"]\n",
        "\n",
        "    def filter_by_token_length(self, example):\n",
        "        # Tokenize the concatenated question + article_body\n",
        "        tokens = self.tokenizer(example[\"question\"], example[\"article_body\"], truncation=False)\n",
        "        return len(tokens[\"input_ids\"]) <= 512\n",
        "\n",
        "    def decode_error(self, example):\n",
        "        input_ids = example[\"input_ids\"]\n",
        "        start_positions = example[\"start_positions\"]\n",
        "        end_positions = example[\"end_positions\"]\n",
        "        predict_answer_tokens = input_ids[start_positions : end_positions+1]\n",
        "        return self.tokenizer.decode(predict_answer_tokens) == example[\"answer\"]\n",
        "\n",
        "    def tokenize_train_function(self, examples):\n",
        "        article_text = [article for article in examples.get(\"article_body\", [\"\"])]\n",
        "        context_text = [context for context in examples.get(\"context\", [\"{}\"])]\n",
        "        answer_text = examples.get(\"answer\", [\"\"])\n",
        "        answer_start = examples.get(\"answer_start\", [0])\n",
        "        context_start_list = examples.get(\"context_start\", [0])\n",
        "        question_text = [q for q in examples.get(\"question\", [\"\"])]\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            question_text,\n",
        "            article_text,\n",
        "            truncation=\"only_second\",  # Truncate only the context\n",
        "            max_length=512,            # Limit input length\n",
        "            stride=128,                # Add a sliding window\n",
        "            return_overflowing_tokens=False,  # Handle long contexts\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "        # sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "        for i, offset in enumerate(offset_mapping):\n",
        "            answer = answer_text[i]\n",
        "            context = context_text[i]\n",
        "            article = article_text[i]\n",
        "            start_char = int(context_start_list[i]) + int(answer_start[i])\n",
        "            end_char = start_char + len(answer)\n",
        "\n",
        "\n",
        "            sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "            # Find the start and end of the context\n",
        "            idx = 0\n",
        "            while sequence_ids[idx] != 1:\n",
        "                idx += 1\n",
        "            context_start = idx\n",
        "            while sequence_ids[idx] == 1:\n",
        "                idx += 1\n",
        "            context_end = idx - 1\n",
        "\n",
        "            # If the answer is not fully inside the context, label is (0, 0)\n",
        "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                # Otherwise it's the start and end token positions\n",
        "                idx = context_start\n",
        "                while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                    idx += 1\n",
        "                start_positions.append(idx - 1)\n",
        "\n",
        "                idx = context_end\n",
        "                while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                    idx -= 1\n",
        "                end_positions.append(idx + 1)\n",
        "\n",
        "        inputs[\"start_positions\"] = start_positions\n",
        "        inputs[\"end_positions\"] = end_positions\n",
        "\n",
        "\n",
        "        return inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGbZ531XfzNW"
      },
      "source": [
        "# QA - BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDCqW6FbfzNW",
        "outputId": "e7f66e70-4719-4eb5-ac95-9cbc628b606d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.26.4\n",
            "[-1.4586302]\n"
          ]
        }
      ],
      "source": [
        "print(np.__version__)  # Check if NumPy is available\n",
        "print(torch.randn(1).numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJwSpyvvp_JZ"
      },
      "outputs": [],
      "source": [
        "qa_bm25 = QA(\n",
        "    model_path=CURRENT_MODEL,\n",
        "    k = 100, overlap=0.0, num_chunks=1)\n",
        "wrong = qa_bm25.evaluate_retriever()\n",
        "metrics = qa_bm25.compute_retrieval_metrics()\n",
        "print(len(wrong))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwp4ApHEfzNX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVStZCd5fzNX"
      },
      "outputs": [],
      "source": [
        "qa_bm25.run()\n",
        "qa_bm25.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk4_nRQlfzNX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXX0NTlEfzNX"
      },
      "source": [
        "# QA - FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvuQYobqfzNX"
      },
      "outputs": [],
      "source": [
        "qa_faiss = QA(\n",
        "    sample=100,\n",
        "    model_path=CURRENT_MODEL,\n",
        "    k = 100, overlap=0.0, num_chunks=1,\n",
        "    indexer_type=FAISS,\n",
        "    use_fine_tuned=True)\n",
        "wrong_faiss = qa_faiss.evaluate_retriever()\n",
        "metrics = qa_faiss.compute_retrieval_metrics()\n",
        "print(len(wrong_faiss))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDx3-H0DfzNX"
      },
      "outputs": [],
      "source": [
        "qa_faiss.run()\n",
        "qa_faiss.evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}